graph(%self.1 : __torch__.___torch_mangle_334.SimpleCNN,
      %x.1 : Tensor):
  %2 : NoneType = prim::Constant()
  %3 : bool = prim::Constant[value=0]()
  %4 : int = prim::Constant[value=2]() # /home/auto_update_valid_train.py:300:24
  %5 : int = prim::Constant[value=3]() # /home/auto_update_valid_train.py:300:27
  %stem.1 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="stem"](%self.1)
  %16 : str = prim::Constant[value="none"]()
  %17 : float = prim::Constant[value=0.10000000000000001]() # :0:0
  %18 : float = prim::Constant[value=1.0000000000000001e-05]() # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:204:12
  %19 : str = prim::Constant[value="builtins.ValueError"]() # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:452:18
  %20 : str = prim::Constant[value="Expected more than 1 value per channel when training, got input size {}"]() # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
  %21 : int = prim::Constant[value=2]() # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:31
  %22 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2821:8
  %23 : int = prim::Constant[value=0]() # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:550:46
  %24 : int = prim::Constant[value=1]() # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:550:33
  %_0.5 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name="0"](%stem.1)
  %_1.5 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="1"](%stem.1)
  %weight.15 : Tensor = prim::GetAttr[name="weight"](%_0.5)
  %bias.15 : Tensor? = prim::GetAttr[name="bias"](%_0.5)
  %29 : int[] = prim::ListConstruct(%24, %24)
  %30 : int[] = prim::ListConstruct(%23, %23)
  %31 : int[] = prim::ListConstruct(%24, %24)
  %input0.5 : Tensor = aten::conv2d(%x.1, %weight.15, %bias.15, %29, %30, %31, %24) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.14 : bool = prim::GetAttr[name="training"](%_1.5)
   = prim::If(%training.14) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.8 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.5)
      %35 : Tensor = aten::add_(%num_batches_tracked.8, %24, %24) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.16 : bool = prim::GetAttr[name="training"](%_1.5)
  %running_mean.8 : Tensor = prim::GetAttr[name="running_mean"](%_1.5)
  %running_var.8 : Tensor = prim::GetAttr[name="running_var"](%_1.5)
  %weight.17 : Tensor = prim::GetAttr[name="weight"](%_1.5)
  %bias.17 : Tensor = prim::GetAttr[name="bias"](%_1.5)
   = prim::If(%training.16) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %41 : int[] = aten::size(%input0.5) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.8 : int = aten::__getitem__(%41, %23) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %43 : int = aten::len(%41) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %44 : int = aten::sub(%43, %21) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.3 : int = prim::Loop(%44, %22, %size_prods.8) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.8 : int, %size_prods0.18 : int):
          %48 : int = aten::add(%i.8, %21) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %49 : int = aten::__getitem__(%41, %48) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.8 : int = aten::mul(%size_prods0.18, %49) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%22, %size_prods1.8)
      %51 : bool = aten::eq(%size_prods0.3, %24) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%51) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %52 : str = aten::format(%20, %41) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%52, %19) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.4 : Tensor = aten::batch_norm(%input0.5, %weight.17, %bias.17, %running_mean.8, %running_var.8, %training.16, %17, %18, %22) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %x0.1 : Tensor = aten::gelu(%input1.4, %16) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %blocks.1 : __torch__.torch.nn.modules.container.___torch_mangle_333.Sequential = prim::GetAttr[name="blocks"](%self.1)
  %55 : int = prim::Constant[value=728]() # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:550:75
  %56 : int = prim::Constant[value=312]() # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:550:75
  %57 : int = prim::Constant[value=144]() # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:550:75
  %58 : int = prim::Constant[value=96]() # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:550:75
  %59 : int = prim::Constant[value=64]() # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:550:75
  %60 : int = prim::Constant[value=1]()
  %61 : str = prim::Constant[value="none"]()
  %62 : float = prim::Constant[value=0.10000000000000001]() # :0:0
  %63 : float = prim::Constant[value=1.0000000000000001e-05]() # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:204:12
  %64 : str = prim::Constant[value="builtins.ValueError"]() # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:452:18
  %65 : str = prim::Constant[value="Expected more than 1 value per channel when training, got input size {}"]() # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
  %66 : int = prim::Constant[value=2]() # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:31
  %67 : bool = prim::Constant[value=1]() # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2821:8
  %68 : int = prim::Constant[value=0]() # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:550:46
  %69 : int = prim::Constant[value=32]() # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:550:75
  %70 : int = prim::Constant[value=-1]() # /home/auto_update_valid_train.py:182:28
  %71 : bool = prim::Constant[value=0]()
  %72 : NoneType = prim::Constant()
  %_0.2 : __torch__.ConvBlock = prim::GetAttr[name="0"](%blocks.1)
  %_1.2 : __torch__.ConvBlock = prim::GetAttr[name="1"](%blocks.1)
  %_2 : __torch__.ConvBlock = prim::GetAttr[name="2"](%blocks.1)
  %_3 : __torch__.ConvBlock = prim::GetAttr[name="3"](%blocks.1)
  %_4 : __torch__.ConvBlock = prim::GetAttr[name="4"](%blocks.1)
  %_5 : __torch__.ConvBlock = prim::GetAttr[name="5"](%blocks.1)
  %_6 : __torch__.ConvBlock = prim::GetAttr[name="6"](%blocks.1)
  %_7 : __torch__.ConvBlock = prim::GetAttr[name="7"](%blocks.1)
  %_8 : __torch__.___torch_mangle_18.ConvBlock = prim::GetAttr[name="8"](%blocks.1)
  %_9 : __torch__.___torch_mangle_29.ConvBlock = prim::GetAttr[name="9"](%blocks.1)
  %_10 : __torch__.___torch_mangle_29.ConvBlock = prim::GetAttr[name="10"](%blocks.1)
  %_11 : __torch__.___torch_mangle_29.ConvBlock = prim::GetAttr[name="11"](%blocks.1)
  %_12 : __torch__.___torch_mangle_307.ConvBlock = prim::GetAttr[name="12"](%blocks.1)
  %_13 : __torch__.___torch_mangle_312.ConvBlock = prim::GetAttr[name="13"](%blocks.1)
  %_14 : __torch__.___torch_mangle_181.ConvBlock = prim::GetAttr[name="14"](%blocks.1)
  %expand_conv.2 : __torch__.torch.nn.modules.container.___torch_mangle_2.Sequential = prim::GetAttr[name="expand_conv"](%_0.2)
  %_0.4 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="0"](%expand_conv.2)
  %_1.4 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="1"](%expand_conv.2)
  %weight.4 : Tensor = prim::GetAttr[name="weight"](%_0.4)
  %bias.4 : Tensor? = prim::GetAttr[name="bias"](%_0.4)
  %93 : int[] = prim::ListConstruct(%60, %60)
  %94 : int[] = prim::ListConstruct(%68, %68)
  %95 : int[] = prim::ListConstruct(%60, %60)
  %input0.7 : Tensor = aten::conv2d(%x0.1, %weight.4, %bias.4, %93, %94, %95, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.3 : bool = prim::GetAttr[name="training"](%_1.4)
   = prim::If(%training.3) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.3 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.4)
      %99 : Tensor = aten::add_(%num_batches_tracked.3, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.5 : bool = prim::GetAttr[name="training"](%_1.4)
  %running_mean.3 : Tensor = prim::GetAttr[name="running_mean"](%_1.4)
  %running_var.3 : Tensor = prim::GetAttr[name="running_var"](%_1.4)
  %weight.6 : Tensor = prim::GetAttr[name="weight"](%_1.4)
  %bias.6 : Tensor = prim::GetAttr[name="bias"](%_1.4)
   = prim::If(%training.5) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %105 : int[] = aten::size(%input0.7) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.3 : int = aten::__getitem__(%105, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %107 : int = aten::len(%105) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %108 : int = aten::sub(%107, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.2 : int = prim::Loop(%108, %67, %size_prods.3) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.3 : int, %size_prods0.9 : int):
          %112 : int = aten::add(%i.3, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %113 : int = aten::__getitem__(%105, %112) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.3 : int = aten::mul(%size_prods0.9, %113) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.3)
      %115 : bool = aten::eq(%size_prods0.2, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%115) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %116 : str = aten::format(%65, %105) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%116, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.5 : Tensor = aten::batch_norm(%input0.7, %weight.6, %bias.6, %running_mean.3, %running_var.3, %training.5, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out.2 : Tensor = aten::gelu(%input1.5, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %depthwise_conv.2 : __torch__.torch.nn.modules.container.___torch_mangle_4.Sequential = prim::GetAttr[name="depthwise_conv"](%_0.2)
  %_0.6 : __torch__.torch.nn.modules.conv.___torch_mangle_3.Conv2d = prim::GetAttr[name="0"](%depthwise_conv.2)
  %_1.6 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="1"](%depthwise_conv.2)
  %weight.8 : Tensor = prim::GetAttr[name="weight"](%_0.6)
  %bias.8 : Tensor? = prim::GetAttr[name="bias"](%_0.6)
  %124 : int[] = prim::ListConstruct(%60, %60)
  %125 : int[] = prim::ListConstruct(%60, %60)
  %126 : int[] = prim::ListConstruct(%60, %60)
  %input0.9 : Tensor = aten::conv2d(%out.2, %weight.8, %bias.8, %124, %125, %126, %69) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.7 : bool = prim::GetAttr[name="training"](%_1.6)
   = prim::If(%training.7) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.5 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.6)
      %130 : Tensor = aten::add_(%num_batches_tracked.5, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.9 : bool = prim::GetAttr[name="training"](%_1.6)
  %running_mean.5 : Tensor = prim::GetAttr[name="running_mean"](%_1.6)
  %running_var.5 : Tensor = prim::GetAttr[name="running_var"](%_1.6)
  %weight.10 : Tensor = prim::GetAttr[name="weight"](%_1.6)
  %bias.10 : Tensor = prim::GetAttr[name="bias"](%_1.6)
   = prim::If(%training.9) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %136 : int[] = aten::size(%input0.9) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.5 : int = aten::__getitem__(%136, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %138 : int = aten::len(%136) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %139 : int = aten::sub(%138, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.11 : int = prim::Loop(%139, %67, %size_prods.5) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.5 : int, %size_prods0.13 : int):
          %143 : int = aten::add(%i.5, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %144 : int = aten::__getitem__(%136, %143) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.5 : int = aten::mul(%size_prods0.13, %144) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.5)
      %146 : bool = aten::eq(%size_prods0.11, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%146) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %147 : str = aten::format(%65, %136) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%147, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.7 : Tensor = aten::batch_norm(%input0.9, %weight.10, %bias.10, %running_mean.5, %running_var.5, %training.9, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out0.2 : Tensor = aten::gelu(%input1.7, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %srm.2 : __torch__.SRMLayer = prim::GetAttr[name="srm"](%_0.2)
  %151 : int[] = aten::size(%out0.2) # /home/auto_update_valid_train.py:179:21
  %b.2 : int, %c.2 : int, %154 : int, %155 : int = prim::ListUnpack(%151)
  %156 : int[] = prim::ListConstruct(%b.2, %c.2, %70)
  %157 : Tensor = aten::view(%out0.2, %156) # /home/auto_update_valid_train.py:182:15
  %158 : int[] = prim::ListConstruct(%70)
  %159 : Tensor = aten::mean(%157, %158, %71, %72) # /home/auto_update_valid_train.py:182:15
  %mean.2 : Tensor = aten::unsqueeze(%159, %70) # /home/auto_update_valid_train.py:182:15
  %161 : int[] = prim::ListConstruct(%b.2, %c.2, %70)
  %162 : Tensor = aten::view(%out0.2, %161) # /home/auto_update_valid_train.py:183:14
  %163 : int[] = prim::ListConstruct(%70)
  %164 : Tensor = aten::std(%162, %163, %67, %71) # /home/auto_update_valid_train.py:183:14
  %std.2 : Tensor = aten::unsqueeze(%164, %70) # /home/auto_update_valid_train.py:183:14
  %166 : Tensor[] = prim::ListConstruct(%mean.2, %std.2)
  %u.2 : Tensor = aten::cat(%166, %70) # /home/auto_update_valid_train.py:184:12
  %cfc.2 : __torch__.torch.nn.modules.conv.Conv1d = prim::GetAttr[name="cfc"](%srm.2)
  %weight.12 : Tensor = prim::GetAttr[name="weight"](%cfc.2)
  %bias.12 : Tensor? = prim::GetAttr[name="bias"](%cfc.2)
  %171 : int[] = prim::ListConstruct(%60)
  %172 : int[] = prim::ListConstruct(%68)
  %173 : int[] = prim::ListConstruct(%60)
  %z.2 : Tensor = aten::conv1d(%u.2, %weight.12, %bias.12, %171, %172, %173, %69) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:370:15
  %bn.2 : __torch__.torch.nn.modules.batchnorm.BatchNorm1d = prim::GetAttr[name="bn"](%srm.2)
  %training.11 : bool = prim::GetAttr[name="training"](%bn.2)
   = prim::If(%training.11) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%bn.2)
      %178 : Tensor = aten::add_(%num_batches_tracked.7, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.13 : bool = prim::GetAttr[name="training"](%bn.2)
  %running_mean.7 : Tensor = prim::GetAttr[name="running_mean"](%bn.2)
  %running_var.7 : Tensor = prim::GetAttr[name="running_var"](%bn.2)
  %weight.14 : Tensor = prim::GetAttr[name="weight"](%bn.2)
  %bias.14 : Tensor = prim::GetAttr[name="bias"](%bn.2)
   = prim::If(%training.13) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %184 : int[] = aten::size(%z.2) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.7 : int = aten::__getitem__(%184, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %186 : int = aten::len(%184) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %187 : int = aten::sub(%186, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.15 : int = prim::Loop(%187, %67, %size_prods.7) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.7 : int, %size_prods0.17 : int):
          %191 : int = aten::add(%i.7, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %192 : int = aten::__getitem__(%184, %191) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.7 : int = aten::mul(%size_prods0.17, %192) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.7)
      %194 : bool = aten::eq(%size_prods0.15, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%194) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %195 : str = aten::format(%65, %184) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%195, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %z0.2 : Tensor = aten::batch_norm(%z.2, %weight.14, %bias.14, %running_mean.7, %running_var.7, %training.13, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %g.2 : Tensor = aten::sigmoid(%z0.2) # /home/auto_update_valid_train.py:189:12
  %198 : int[] = prim::ListConstruct(%b.2, %c.2, %60, %60)
  %g0.2 : Tensor = aten::view(%g.2, %198) # /home/auto_update_valid_train.py:190:12
  %200 : Tensor = aten::expand_as(%g0.2, %out0.2) # /home/auto_update_valid_train.py:192:19
  %out1.2 : Tensor = aten::mul(%out0.2, %200) # /home/auto_update_valid_train.py:192:15
  %project_conv.2 : __torch__.torch.nn.modules.container.___torch_mangle_6.Sequential = prim::GetAttr[name="project_conv"](%_0.2)
  %_0.8 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="0"](%project_conv.2)
  %_1.8 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="1"](%project_conv.2)
  %weight.16 : Tensor = prim::GetAttr[name="weight"](%_0.8)
  %bias.16 : Tensor? = prim::GetAttr[name="bias"](%_0.8)
  %207 : int[] = prim::ListConstruct(%60, %60)
  %208 : int[] = prim::ListConstruct(%68, %68)
  %209 : int[] = prim::ListConstruct(%60, %60)
  %input0.11 : Tensor = aten::conv2d(%out1.2, %weight.16, %bias.16, %207, %208, %209, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.15 : bool = prim::GetAttr[name="training"](%_1.8)
   = prim::If(%training.15) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.9 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.8)
      %213 : Tensor = aten::add_(%num_batches_tracked.9, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.17 : bool = prim::GetAttr[name="training"](%_1.8)
  %running_mean.9 : Tensor = prim::GetAttr[name="running_mean"](%_1.8)
  %running_var.9 : Tensor = prim::GetAttr[name="running_var"](%_1.8)
  %weight.18 : Tensor = prim::GetAttr[name="weight"](%_1.8)
  %bias.18 : Tensor = prim::GetAttr[name="bias"](%_1.8)
   = prim::If(%training.17) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %219 : int[] = aten::size(%input0.11) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.9 : int = aten::__getitem__(%219, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %221 : int = aten::len(%219) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %222 : int = aten::sub(%221, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.19 : int = prim::Loop(%222, %67, %size_prods.9) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.9 : int, %size_prods0.21 : int):
          %226 : int = aten::add(%i.9, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %227 : int = aten::__getitem__(%219, %226) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.9 : int = aten::mul(%size_prods0.21, %227) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.9)
      %229 : bool = aten::eq(%size_prods0.19, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%229) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %230 : str = aten::format(%65, %219) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%230, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out2.2 : Tensor = aten::batch_norm(%input0.11, %weight.18, %bias.18, %running_mean.9, %running_var.9, %training.17, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %use_residual.2 : bool = prim::GetAttr[name="use_residual"](%_0.2)
  %input0.3 : Tensor = prim::If(%use_residual.2) # /home/auto_update_valid_train.py:261:8
    block0():
      %out3.2 : Tensor = aten::add(%out2.2, %x0.1, %60) # /home/auto_update_valid_train.py:263:18
      -> (%out3.2)
    block1():
      -> (%out2.2)
  %expand_conv.4 : __torch__.torch.nn.modules.container.___torch_mangle_2.Sequential = prim::GetAttr[name="expand_conv"](%_1.2)
  %_0.10 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="0"](%expand_conv.4)
  %_1.10 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="1"](%expand_conv.4)
  %weight.20 : Tensor = prim::GetAttr[name="weight"](%_0.10)
  %bias.20 : Tensor? = prim::GetAttr[name="bias"](%_0.10)
  %240 : int[] = prim::ListConstruct(%60, %60)
  %241 : int[] = prim::ListConstruct(%68, %68)
  %242 : int[] = prim::ListConstruct(%60, %60)
  %input0.13 : Tensor = aten::conv2d(%input0.3, %weight.20, %bias.20, %240, %241, %242, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.19 : bool = prim::GetAttr[name="training"](%_1.10)
   = prim::If(%training.19) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.11 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.10)
      %246 : Tensor = aten::add_(%num_batches_tracked.11, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.21 : bool = prim::GetAttr[name="training"](%_1.10)
  %running_mean.11 : Tensor = prim::GetAttr[name="running_mean"](%_1.10)
  %running_var.11 : Tensor = prim::GetAttr[name="running_var"](%_1.10)
  %weight.22 : Tensor = prim::GetAttr[name="weight"](%_1.10)
  %bias.22 : Tensor = prim::GetAttr[name="bias"](%_1.10)
   = prim::If(%training.21) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %252 : int[] = aten::size(%input0.13) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.11 : int = aten::__getitem__(%252, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %254 : int = aten::len(%252) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %255 : int = aten::sub(%254, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.23 : int = prim::Loop(%255, %67, %size_prods.11) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.11 : int, %size_prods0.25 : int):
          %259 : int = aten::add(%i.11, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %260 : int = aten::__getitem__(%252, %259) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.11 : int = aten::mul(%size_prods0.25, %260) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.11)
      %262 : bool = aten::eq(%size_prods0.23, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%262) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %263 : str = aten::format(%65, %252) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%263, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.11 : Tensor = aten::batch_norm(%input0.13, %weight.22, %bias.22, %running_mean.11, %running_var.11, %training.21, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out.4 : Tensor = aten::gelu(%input1.11, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %depthwise_conv.4 : __torch__.torch.nn.modules.container.___torch_mangle_4.Sequential = prim::GetAttr[name="depthwise_conv"](%_1.2)
  %_0.12 : __torch__.torch.nn.modules.conv.___torch_mangle_3.Conv2d = prim::GetAttr[name="0"](%depthwise_conv.4)
  %_1.12 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="1"](%depthwise_conv.4)
  %weight.24 : Tensor = prim::GetAttr[name="weight"](%_0.12)
  %bias.24 : Tensor? = prim::GetAttr[name="bias"](%_0.12)
  %271 : int[] = prim::ListConstruct(%60, %60)
  %272 : int[] = prim::ListConstruct(%60, %60)
  %273 : int[] = prim::ListConstruct(%60, %60)
  %input0.15 : Tensor = aten::conv2d(%out.4, %weight.24, %bias.24, %271, %272, %273, %69) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.23 : bool = prim::GetAttr[name="training"](%_1.12)
   = prim::If(%training.23) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.13 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.12)
      %277 : Tensor = aten::add_(%num_batches_tracked.13, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.25 : bool = prim::GetAttr[name="training"](%_1.12)
  %running_mean.13 : Tensor = prim::GetAttr[name="running_mean"](%_1.12)
  %running_var.13 : Tensor = prim::GetAttr[name="running_var"](%_1.12)
  %weight.26 : Tensor = prim::GetAttr[name="weight"](%_1.12)
  %bias.26 : Tensor = prim::GetAttr[name="bias"](%_1.12)
   = prim::If(%training.25) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %283 : int[] = aten::size(%input0.15) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.13 : int = aten::__getitem__(%283, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %285 : int = aten::len(%283) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %286 : int = aten::sub(%285, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.27 : int = prim::Loop(%286, %67, %size_prods.13) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.13 : int, %size_prods0.29 : int):
          %290 : int = aten::add(%i.13, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %291 : int = aten::__getitem__(%283, %290) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.13 : int = aten::mul(%size_prods0.29, %291) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.13)
      %293 : bool = aten::eq(%size_prods0.27, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%293) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %294 : str = aten::format(%65, %283) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%294, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.13 : Tensor = aten::batch_norm(%input0.15, %weight.26, %bias.26, %running_mean.13, %running_var.13, %training.25, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out0.4 : Tensor = aten::gelu(%input1.13, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %srm.4 : __torch__.SRMLayer = prim::GetAttr[name="srm"](%_1.2)
  %298 : int[] = aten::size(%out0.4) # /home/auto_update_valid_train.py:179:21
  %b.4 : int, %c.4 : int, %301 : int, %302 : int = prim::ListUnpack(%298)
  %303 : int[] = prim::ListConstruct(%b.4, %c.4, %70)
  %304 : Tensor = aten::view(%out0.4, %303) # /home/auto_update_valid_train.py:182:15
  %305 : int[] = prim::ListConstruct(%70)
  %306 : Tensor = aten::mean(%304, %305, %71, %72) # /home/auto_update_valid_train.py:182:15
  %mean.4 : Tensor = aten::unsqueeze(%306, %70) # /home/auto_update_valid_train.py:182:15
  %308 : int[] = prim::ListConstruct(%b.4, %c.4, %70)
  %309 : Tensor = aten::view(%out0.4, %308) # /home/auto_update_valid_train.py:183:14
  %310 : int[] = prim::ListConstruct(%70)
  %311 : Tensor = aten::std(%309, %310, %67, %71) # /home/auto_update_valid_train.py:183:14
  %std.4 : Tensor = aten::unsqueeze(%311, %70) # /home/auto_update_valid_train.py:183:14
  %313 : Tensor[] = prim::ListConstruct(%mean.4, %std.4)
  %u.4 : Tensor = aten::cat(%313, %70) # /home/auto_update_valid_train.py:184:12
  %cfc.4 : __torch__.torch.nn.modules.conv.Conv1d = prim::GetAttr[name="cfc"](%srm.4)
  %weight.28 : Tensor = prim::GetAttr[name="weight"](%cfc.4)
  %bias.28 : Tensor? = prim::GetAttr[name="bias"](%cfc.4)
  %318 : int[] = prim::ListConstruct(%60)
  %319 : int[] = prim::ListConstruct(%68)
  %320 : int[] = prim::ListConstruct(%60)
  %z.4 : Tensor = aten::conv1d(%u.4, %weight.28, %bias.28, %318, %319, %320, %69) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:370:15
  %bn.4 : __torch__.torch.nn.modules.batchnorm.BatchNorm1d = prim::GetAttr[name="bn"](%srm.4)
  %training.27 : bool = prim::GetAttr[name="training"](%bn.4)
   = prim::If(%training.27) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.15 : Tensor = prim::GetAttr[name="num_batches_tracked"](%bn.4)
      %325 : Tensor = aten::add_(%num_batches_tracked.15, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.29 : bool = prim::GetAttr[name="training"](%bn.4)
  %running_mean.15 : Tensor = prim::GetAttr[name="running_mean"](%bn.4)
  %running_var.15 : Tensor = prim::GetAttr[name="running_var"](%bn.4)
  %weight.30 : Tensor = prim::GetAttr[name="weight"](%bn.4)
  %bias.30 : Tensor = prim::GetAttr[name="bias"](%bn.4)
   = prim::If(%training.29) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %331 : int[] = aten::size(%z.4) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.15 : int = aten::__getitem__(%331, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %333 : int = aten::len(%331) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %334 : int = aten::sub(%333, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.31 : int = prim::Loop(%334, %67, %size_prods.15) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.15 : int, %size_prods0.33 : int):
          %338 : int = aten::add(%i.15, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %339 : int = aten::__getitem__(%331, %338) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.15 : int = aten::mul(%size_prods0.33, %339) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.15)
      %341 : bool = aten::eq(%size_prods0.31, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%341) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %342 : str = aten::format(%65, %331) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%342, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %z0.4 : Tensor = aten::batch_norm(%z.4, %weight.30, %bias.30, %running_mean.15, %running_var.15, %training.29, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %g.4 : Tensor = aten::sigmoid(%z0.4) # /home/auto_update_valid_train.py:189:12
  %345 : int[] = prim::ListConstruct(%b.4, %c.4, %60, %60)
  %g0.4 : Tensor = aten::view(%g.4, %345) # /home/auto_update_valid_train.py:190:12
  %347 : Tensor = aten::expand_as(%g0.4, %out0.4) # /home/auto_update_valid_train.py:192:19
  %out1.4 : Tensor = aten::mul(%out0.4, %347) # /home/auto_update_valid_train.py:192:15
  %project_conv.4 : __torch__.torch.nn.modules.container.___torch_mangle_6.Sequential = prim::GetAttr[name="project_conv"](%_1.2)
  %_0.14 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="0"](%project_conv.4)
  %_1.14 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="1"](%project_conv.4)
  %weight.32 : Tensor = prim::GetAttr[name="weight"](%_0.14)
  %bias.32 : Tensor? = prim::GetAttr[name="bias"](%_0.14)
  %354 : int[] = prim::ListConstruct(%60, %60)
  %355 : int[] = prim::ListConstruct(%68, %68)
  %356 : int[] = prim::ListConstruct(%60, %60)
  %input0.17 : Tensor = aten::conv2d(%out1.4, %weight.32, %bias.32, %354, %355, %356, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.31 : bool = prim::GetAttr[name="training"](%_1.14)
   = prim::If(%training.31) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.17 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.14)
      %360 : Tensor = aten::add_(%num_batches_tracked.17, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.33 : bool = prim::GetAttr[name="training"](%_1.14)
  %running_mean.17 : Tensor = prim::GetAttr[name="running_mean"](%_1.14)
  %running_var.17 : Tensor = prim::GetAttr[name="running_var"](%_1.14)
  %weight.34 : Tensor = prim::GetAttr[name="weight"](%_1.14)
  %bias.34 : Tensor = prim::GetAttr[name="bias"](%_1.14)
   = prim::If(%training.33) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %366 : int[] = aten::size(%input0.17) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.17 : int = aten::__getitem__(%366, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %368 : int = aten::len(%366) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %369 : int = aten::sub(%368, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.35 : int = prim::Loop(%369, %67, %size_prods.17) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.17 : int, %size_prods0.37 : int):
          %373 : int = aten::add(%i.17, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %374 : int = aten::__getitem__(%366, %373) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.17 : int = aten::mul(%size_prods0.37, %374) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.17)
      %376 : bool = aten::eq(%size_prods0.35, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%376) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %377 : str = aten::format(%65, %366) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%377, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out2.4 : Tensor = aten::batch_norm(%input0.17, %weight.34, %bias.34, %running_mean.17, %running_var.17, %training.33, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %use_residual.4 : bool = prim::GetAttr[name="use_residual"](%_1.2)
  %input1.3 : Tensor = prim::If(%use_residual.4) # /home/auto_update_valid_train.py:261:8
    block0():
      %out3.4 : Tensor = aten::add(%out2.4, %input0.3, %60) # /home/auto_update_valid_train.py:263:18
      -> (%out3.4)
    block1():
      -> (%out2.4)
  %expand_conv.6 : __torch__.torch.nn.modules.container.___torch_mangle_2.Sequential = prim::GetAttr[name="expand_conv"](%_2)
  %_0.16 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="0"](%expand_conv.6)
  %_1.16 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="1"](%expand_conv.6)
  %weight.36 : Tensor = prim::GetAttr[name="weight"](%_0.16)
  %bias.36 : Tensor? = prim::GetAttr[name="bias"](%_0.16)
  %387 : int[] = prim::ListConstruct(%60, %60)
  %388 : int[] = prim::ListConstruct(%68, %68)
  %389 : int[] = prim::ListConstruct(%60, %60)
  %input0.19 : Tensor = aten::conv2d(%input1.3, %weight.36, %bias.36, %387, %388, %389, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.35 : bool = prim::GetAttr[name="training"](%_1.16)
   = prim::If(%training.35) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.19 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.16)
      %393 : Tensor = aten::add_(%num_batches_tracked.19, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.37 : bool = prim::GetAttr[name="training"](%_1.16)
  %running_mean.19 : Tensor = prim::GetAttr[name="running_mean"](%_1.16)
  %running_var.19 : Tensor = prim::GetAttr[name="running_var"](%_1.16)
  %weight.38 : Tensor = prim::GetAttr[name="weight"](%_1.16)
  %bias.38 : Tensor = prim::GetAttr[name="bias"](%_1.16)
   = prim::If(%training.37) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %399 : int[] = aten::size(%input0.19) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.19 : int = aten::__getitem__(%399, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %401 : int = aten::len(%399) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %402 : int = aten::sub(%401, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.39 : int = prim::Loop(%402, %67, %size_prods.19) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.19 : int, %size_prods0.41 : int):
          %406 : int = aten::add(%i.19, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %407 : int = aten::__getitem__(%399, %406) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.19 : int = aten::mul(%size_prods0.41, %407) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.19)
      %409 : bool = aten::eq(%size_prods0.39, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%409) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %410 : str = aten::format(%65, %399) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%410, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.15 : Tensor = aten::batch_norm(%input0.19, %weight.38, %bias.38, %running_mean.19, %running_var.19, %training.37, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out.6 : Tensor = aten::gelu(%input1.15, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %depthwise_conv.6 : __torch__.torch.nn.modules.container.___torch_mangle_4.Sequential = prim::GetAttr[name="depthwise_conv"](%_2)
  %_0.18 : __torch__.torch.nn.modules.conv.___torch_mangle_3.Conv2d = prim::GetAttr[name="0"](%depthwise_conv.6)
  %_1.18 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="1"](%depthwise_conv.6)
  %weight.40 : Tensor = prim::GetAttr[name="weight"](%_0.18)
  %bias.40 : Tensor? = prim::GetAttr[name="bias"](%_0.18)
  %418 : int[] = prim::ListConstruct(%60, %60)
  %419 : int[] = prim::ListConstruct(%60, %60)
  %420 : int[] = prim::ListConstruct(%60, %60)
  %input0.21 : Tensor = aten::conv2d(%out.6, %weight.40, %bias.40, %418, %419, %420, %69) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.39 : bool = prim::GetAttr[name="training"](%_1.18)
   = prim::If(%training.39) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.21 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.18)
      %424 : Tensor = aten::add_(%num_batches_tracked.21, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.41 : bool = prim::GetAttr[name="training"](%_1.18)
  %running_mean.21 : Tensor = prim::GetAttr[name="running_mean"](%_1.18)
  %running_var.21 : Tensor = prim::GetAttr[name="running_var"](%_1.18)
  %weight.42 : Tensor = prim::GetAttr[name="weight"](%_1.18)
  %bias.42 : Tensor = prim::GetAttr[name="bias"](%_1.18)
   = prim::If(%training.41) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %430 : int[] = aten::size(%input0.21) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.21 : int = aten::__getitem__(%430, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %432 : int = aten::len(%430) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %433 : int = aten::sub(%432, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.43 : int = prim::Loop(%433, %67, %size_prods.21) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.21 : int, %size_prods0.45 : int):
          %437 : int = aten::add(%i.21, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %438 : int = aten::__getitem__(%430, %437) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.21 : int = aten::mul(%size_prods0.45, %438) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.21)
      %440 : bool = aten::eq(%size_prods0.43, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%440) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %441 : str = aten::format(%65, %430) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%441, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.17 : Tensor = aten::batch_norm(%input0.21, %weight.42, %bias.42, %running_mean.21, %running_var.21, %training.41, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out0.6 : Tensor = aten::gelu(%input1.17, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %srm.6 : __torch__.SRMLayer = prim::GetAttr[name="srm"](%_2)
  %445 : int[] = aten::size(%out0.6) # /home/auto_update_valid_train.py:179:21
  %b.6 : int, %c.6 : int, %448 : int, %449 : int = prim::ListUnpack(%445)
  %450 : int[] = prim::ListConstruct(%b.6, %c.6, %70)
  %451 : Tensor = aten::view(%out0.6, %450) # /home/auto_update_valid_train.py:182:15
  %452 : int[] = prim::ListConstruct(%70)
  %453 : Tensor = aten::mean(%451, %452, %71, %72) # /home/auto_update_valid_train.py:182:15
  %mean.6 : Tensor = aten::unsqueeze(%453, %70) # /home/auto_update_valid_train.py:182:15
  %455 : int[] = prim::ListConstruct(%b.6, %c.6, %70)
  %456 : Tensor = aten::view(%out0.6, %455) # /home/auto_update_valid_train.py:183:14
  %457 : int[] = prim::ListConstruct(%70)
  %458 : Tensor = aten::std(%456, %457, %67, %71) # /home/auto_update_valid_train.py:183:14
  %std.6 : Tensor = aten::unsqueeze(%458, %70) # /home/auto_update_valid_train.py:183:14
  %460 : Tensor[] = prim::ListConstruct(%mean.6, %std.6)
  %u.6 : Tensor = aten::cat(%460, %70) # /home/auto_update_valid_train.py:184:12
  %cfc.6 : __torch__.torch.nn.modules.conv.Conv1d = prim::GetAttr[name="cfc"](%srm.6)
  %weight.44 : Tensor = prim::GetAttr[name="weight"](%cfc.6)
  %bias.44 : Tensor? = prim::GetAttr[name="bias"](%cfc.6)
  %465 : int[] = prim::ListConstruct(%60)
  %466 : int[] = prim::ListConstruct(%68)
  %467 : int[] = prim::ListConstruct(%60)
  %z.6 : Tensor = aten::conv1d(%u.6, %weight.44, %bias.44, %465, %466, %467, %69) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:370:15
  %bn.6 : __torch__.torch.nn.modules.batchnorm.BatchNorm1d = prim::GetAttr[name="bn"](%srm.6)
  %training.43 : bool = prim::GetAttr[name="training"](%bn.6)
   = prim::If(%training.43) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.23 : Tensor = prim::GetAttr[name="num_batches_tracked"](%bn.6)
      %472 : Tensor = aten::add_(%num_batches_tracked.23, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.45 : bool = prim::GetAttr[name="training"](%bn.6)
  %running_mean.23 : Tensor = prim::GetAttr[name="running_mean"](%bn.6)
  %running_var.23 : Tensor = prim::GetAttr[name="running_var"](%bn.6)
  %weight.46 : Tensor = prim::GetAttr[name="weight"](%bn.6)
  %bias.46 : Tensor = prim::GetAttr[name="bias"](%bn.6)
   = prim::If(%training.45) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %478 : int[] = aten::size(%z.6) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.23 : int = aten::__getitem__(%478, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %480 : int = aten::len(%478) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %481 : int = aten::sub(%480, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.47 : int = prim::Loop(%481, %67, %size_prods.23) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.23 : int, %size_prods0.49 : int):
          %485 : int = aten::add(%i.23, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %486 : int = aten::__getitem__(%478, %485) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.23 : int = aten::mul(%size_prods0.49, %486) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.23)
      %488 : bool = aten::eq(%size_prods0.47, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%488) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %489 : str = aten::format(%65, %478) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%489, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %z0.6 : Tensor = aten::batch_norm(%z.6, %weight.46, %bias.46, %running_mean.23, %running_var.23, %training.45, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %g.6 : Tensor = aten::sigmoid(%z0.6) # /home/auto_update_valid_train.py:189:12
  %492 : int[] = prim::ListConstruct(%b.6, %c.6, %60, %60)
  %g0.6 : Tensor = aten::view(%g.6, %492) # /home/auto_update_valid_train.py:190:12
  %494 : Tensor = aten::expand_as(%g0.6, %out0.6) # /home/auto_update_valid_train.py:192:19
  %out1.6 : Tensor = aten::mul(%out0.6, %494) # /home/auto_update_valid_train.py:192:15
  %project_conv.6 : __torch__.torch.nn.modules.container.___torch_mangle_6.Sequential = prim::GetAttr[name="project_conv"](%_2)
  %_0.20 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="0"](%project_conv.6)
  %_1.20 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="1"](%project_conv.6)
  %weight.48 : Tensor = prim::GetAttr[name="weight"](%_0.20)
  %bias.48 : Tensor? = prim::GetAttr[name="bias"](%_0.20)
  %501 : int[] = prim::ListConstruct(%60, %60)
  %502 : int[] = prim::ListConstruct(%68, %68)
  %503 : int[] = prim::ListConstruct(%60, %60)
  %input0.23 : Tensor = aten::conv2d(%out1.6, %weight.48, %bias.48, %501, %502, %503, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.47 : bool = prim::GetAttr[name="training"](%_1.20)
   = prim::If(%training.47) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.25 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.20)
      %507 : Tensor = aten::add_(%num_batches_tracked.25, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.49 : bool = prim::GetAttr[name="training"](%_1.20)
  %running_mean.25 : Tensor = prim::GetAttr[name="running_mean"](%_1.20)
  %running_var.25 : Tensor = prim::GetAttr[name="running_var"](%_1.20)
  %weight.50 : Tensor = prim::GetAttr[name="weight"](%_1.20)
  %bias.50 : Tensor = prim::GetAttr[name="bias"](%_1.20)
   = prim::If(%training.49) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %513 : int[] = aten::size(%input0.23) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.25 : int = aten::__getitem__(%513, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %515 : int = aten::len(%513) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %516 : int = aten::sub(%515, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.51 : int = prim::Loop(%516, %67, %size_prods.25) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.25 : int, %size_prods0.53 : int):
          %520 : int = aten::add(%i.25, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %521 : int = aten::__getitem__(%513, %520) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.25 : int = aten::mul(%size_prods0.53, %521) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.25)
      %523 : bool = aten::eq(%size_prods0.51, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%523) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %524 : str = aten::format(%65, %513) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%524, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out2.6 : Tensor = aten::batch_norm(%input0.23, %weight.50, %bias.50, %running_mean.25, %running_var.25, %training.49, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %use_residual.6 : bool = prim::GetAttr[name="use_residual"](%_2)
  %input2.1 : Tensor = prim::If(%use_residual.6) # /home/auto_update_valid_train.py:261:8
    block0():
      %out3.6 : Tensor = aten::add(%out2.6, %input1.3, %60) # /home/auto_update_valid_train.py:263:18
      -> (%out3.6)
    block1():
      -> (%out2.6)
  %expand_conv.8 : __torch__.torch.nn.modules.container.___torch_mangle_2.Sequential = prim::GetAttr[name="expand_conv"](%_3)
  %_0.22 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="0"](%expand_conv.8)
  %_1.22 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="1"](%expand_conv.8)
  %weight.52 : Tensor = prim::GetAttr[name="weight"](%_0.22)
  %bias.52 : Tensor? = prim::GetAttr[name="bias"](%_0.22)
  %534 : int[] = prim::ListConstruct(%60, %60)
  %535 : int[] = prim::ListConstruct(%68, %68)
  %536 : int[] = prim::ListConstruct(%60, %60)
  %input0.25 : Tensor = aten::conv2d(%input2.1, %weight.52, %bias.52, %534, %535, %536, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.51 : bool = prim::GetAttr[name="training"](%_1.22)
   = prim::If(%training.51) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.27 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.22)
      %540 : Tensor = aten::add_(%num_batches_tracked.27, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.53 : bool = prim::GetAttr[name="training"](%_1.22)
  %running_mean.27 : Tensor = prim::GetAttr[name="running_mean"](%_1.22)
  %running_var.27 : Tensor = prim::GetAttr[name="running_var"](%_1.22)
  %weight.54 : Tensor = prim::GetAttr[name="weight"](%_1.22)
  %bias.54 : Tensor = prim::GetAttr[name="bias"](%_1.22)
   = prim::If(%training.53) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %546 : int[] = aten::size(%input0.25) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.27 : int = aten::__getitem__(%546, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %548 : int = aten::len(%546) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %549 : int = aten::sub(%548, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.55 : int = prim::Loop(%549, %67, %size_prods.27) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.27 : int, %size_prods0.57 : int):
          %553 : int = aten::add(%i.27, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %554 : int = aten::__getitem__(%546, %553) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.27 : int = aten::mul(%size_prods0.57, %554) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.27)
      %556 : bool = aten::eq(%size_prods0.55, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%556) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %557 : str = aten::format(%65, %546) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%557, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.19 : Tensor = aten::batch_norm(%input0.25, %weight.54, %bias.54, %running_mean.27, %running_var.27, %training.53, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out.8 : Tensor = aten::gelu(%input1.19, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %depthwise_conv.8 : __torch__.torch.nn.modules.container.___torch_mangle_4.Sequential = prim::GetAttr[name="depthwise_conv"](%_3)
  %_0.24 : __torch__.torch.nn.modules.conv.___torch_mangle_3.Conv2d = prim::GetAttr[name="0"](%depthwise_conv.8)
  %_1.24 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="1"](%depthwise_conv.8)
  %weight.56 : Tensor = prim::GetAttr[name="weight"](%_0.24)
  %bias.56 : Tensor? = prim::GetAttr[name="bias"](%_0.24)
  %565 : int[] = prim::ListConstruct(%60, %60)
  %566 : int[] = prim::ListConstruct(%60, %60)
  %567 : int[] = prim::ListConstruct(%60, %60)
  %input0.27 : Tensor = aten::conv2d(%out.8, %weight.56, %bias.56, %565, %566, %567, %69) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.55 : bool = prim::GetAttr[name="training"](%_1.24)
   = prim::If(%training.55) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.29 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.24)
      %571 : Tensor = aten::add_(%num_batches_tracked.29, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.57 : bool = prim::GetAttr[name="training"](%_1.24)
  %running_mean.29 : Tensor = prim::GetAttr[name="running_mean"](%_1.24)
  %running_var.29 : Tensor = prim::GetAttr[name="running_var"](%_1.24)
  %weight.58 : Tensor = prim::GetAttr[name="weight"](%_1.24)
  %bias.58 : Tensor = prim::GetAttr[name="bias"](%_1.24)
   = prim::If(%training.57) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %577 : int[] = aten::size(%input0.27) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.29 : int = aten::__getitem__(%577, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %579 : int = aten::len(%577) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %580 : int = aten::sub(%579, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.59 : int = prim::Loop(%580, %67, %size_prods.29) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.29 : int, %size_prods0.61 : int):
          %584 : int = aten::add(%i.29, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %585 : int = aten::__getitem__(%577, %584) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.29 : int = aten::mul(%size_prods0.61, %585) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.29)
      %587 : bool = aten::eq(%size_prods0.59, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%587) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %588 : str = aten::format(%65, %577) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%588, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.21 : Tensor = aten::batch_norm(%input0.27, %weight.58, %bias.58, %running_mean.29, %running_var.29, %training.57, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out0.8 : Tensor = aten::gelu(%input1.21, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %srm.8 : __torch__.SRMLayer = prim::GetAttr[name="srm"](%_3)
  %592 : int[] = aten::size(%out0.8) # /home/auto_update_valid_train.py:179:21
  %b.8 : int, %c.8 : int, %595 : int, %596 : int = prim::ListUnpack(%592)
  %597 : int[] = prim::ListConstruct(%b.8, %c.8, %70)
  %598 : Tensor = aten::view(%out0.8, %597) # /home/auto_update_valid_train.py:182:15
  %599 : int[] = prim::ListConstruct(%70)
  %600 : Tensor = aten::mean(%598, %599, %71, %72) # /home/auto_update_valid_train.py:182:15
  %mean.8 : Tensor = aten::unsqueeze(%600, %70) # /home/auto_update_valid_train.py:182:15
  %602 : int[] = prim::ListConstruct(%b.8, %c.8, %70)
  %603 : Tensor = aten::view(%out0.8, %602) # /home/auto_update_valid_train.py:183:14
  %604 : int[] = prim::ListConstruct(%70)
  %605 : Tensor = aten::std(%603, %604, %67, %71) # /home/auto_update_valid_train.py:183:14
  %std.8 : Tensor = aten::unsqueeze(%605, %70) # /home/auto_update_valid_train.py:183:14
  %607 : Tensor[] = prim::ListConstruct(%mean.8, %std.8)
  %u.8 : Tensor = aten::cat(%607, %70) # /home/auto_update_valid_train.py:184:12
  %cfc.8 : __torch__.torch.nn.modules.conv.Conv1d = prim::GetAttr[name="cfc"](%srm.8)
  %weight.60 : Tensor = prim::GetAttr[name="weight"](%cfc.8)
  %bias.60 : Tensor? = prim::GetAttr[name="bias"](%cfc.8)
  %612 : int[] = prim::ListConstruct(%60)
  %613 : int[] = prim::ListConstruct(%68)
  %614 : int[] = prim::ListConstruct(%60)
  %z.8 : Tensor = aten::conv1d(%u.8, %weight.60, %bias.60, %612, %613, %614, %69) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:370:15
  %bn.8 : __torch__.torch.nn.modules.batchnorm.BatchNorm1d = prim::GetAttr[name="bn"](%srm.8)
  %training.59 : bool = prim::GetAttr[name="training"](%bn.8)
   = prim::If(%training.59) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.31 : Tensor = prim::GetAttr[name="num_batches_tracked"](%bn.8)
      %619 : Tensor = aten::add_(%num_batches_tracked.31, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.61 : bool = prim::GetAttr[name="training"](%bn.8)
  %running_mean.31 : Tensor = prim::GetAttr[name="running_mean"](%bn.8)
  %running_var.31 : Tensor = prim::GetAttr[name="running_var"](%bn.8)
  %weight.62 : Tensor = prim::GetAttr[name="weight"](%bn.8)
  %bias.62 : Tensor = prim::GetAttr[name="bias"](%bn.8)
   = prim::If(%training.61) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %625 : int[] = aten::size(%z.8) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.31 : int = aten::__getitem__(%625, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %627 : int = aten::len(%625) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %628 : int = aten::sub(%627, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.63 : int = prim::Loop(%628, %67, %size_prods.31) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.31 : int, %size_prods0.65 : int):
          %632 : int = aten::add(%i.31, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %633 : int = aten::__getitem__(%625, %632) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.31 : int = aten::mul(%size_prods0.65, %633) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.31)
      %635 : bool = aten::eq(%size_prods0.63, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%635) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %636 : str = aten::format(%65, %625) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%636, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %z0.8 : Tensor = aten::batch_norm(%z.8, %weight.62, %bias.62, %running_mean.31, %running_var.31, %training.61, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %g.8 : Tensor = aten::sigmoid(%z0.8) # /home/auto_update_valid_train.py:189:12
  %639 : int[] = prim::ListConstruct(%b.8, %c.8, %60, %60)
  %g0.8 : Tensor = aten::view(%g.8, %639) # /home/auto_update_valid_train.py:190:12
  %641 : Tensor = aten::expand_as(%g0.8, %out0.8) # /home/auto_update_valid_train.py:192:19
  %out1.8 : Tensor = aten::mul(%out0.8, %641) # /home/auto_update_valid_train.py:192:15
  %project_conv.8 : __torch__.torch.nn.modules.container.___torch_mangle_6.Sequential = prim::GetAttr[name="project_conv"](%_3)
  %_0.26 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="0"](%project_conv.8)
  %_1.26 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="1"](%project_conv.8)
  %weight.64 : Tensor = prim::GetAttr[name="weight"](%_0.26)
  %bias.64 : Tensor? = prim::GetAttr[name="bias"](%_0.26)
  %648 : int[] = prim::ListConstruct(%60, %60)
  %649 : int[] = prim::ListConstruct(%68, %68)
  %650 : int[] = prim::ListConstruct(%60, %60)
  %input0.29 : Tensor = aten::conv2d(%out1.8, %weight.64, %bias.64, %648, %649, %650, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.63 : bool = prim::GetAttr[name="training"](%_1.26)
   = prim::If(%training.63) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.33 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.26)
      %654 : Tensor = aten::add_(%num_batches_tracked.33, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.65 : bool = prim::GetAttr[name="training"](%_1.26)
  %running_mean.33 : Tensor = prim::GetAttr[name="running_mean"](%_1.26)
  %running_var.33 : Tensor = prim::GetAttr[name="running_var"](%_1.26)
  %weight.66 : Tensor = prim::GetAttr[name="weight"](%_1.26)
  %bias.66 : Tensor = prim::GetAttr[name="bias"](%_1.26)
   = prim::If(%training.65) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %660 : int[] = aten::size(%input0.29) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.33 : int = aten::__getitem__(%660, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %662 : int = aten::len(%660) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %663 : int = aten::sub(%662, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.67 : int = prim::Loop(%663, %67, %size_prods.33) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.33 : int, %size_prods0.69 : int):
          %667 : int = aten::add(%i.33, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %668 : int = aten::__getitem__(%660, %667) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.33 : int = aten::mul(%size_prods0.69, %668) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.33)
      %670 : bool = aten::eq(%size_prods0.67, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%670) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %671 : str = aten::format(%65, %660) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%671, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out2.8 : Tensor = aten::batch_norm(%input0.29, %weight.66, %bias.66, %running_mean.33, %running_var.33, %training.65, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %use_residual.8 : bool = prim::GetAttr[name="use_residual"](%_3)
  %input3.1 : Tensor = prim::If(%use_residual.8) # /home/auto_update_valid_train.py:261:8
    block0():
      %out3.8 : Tensor = aten::add(%out2.8, %input2.1, %60) # /home/auto_update_valid_train.py:263:18
      -> (%out3.8)
    block1():
      -> (%out2.8)
  %expand_conv.10 : __torch__.torch.nn.modules.container.___torch_mangle_2.Sequential = prim::GetAttr[name="expand_conv"](%_4)
  %_0.28 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="0"](%expand_conv.10)
  %_1.28 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="1"](%expand_conv.10)
  %weight.68 : Tensor = prim::GetAttr[name="weight"](%_0.28)
  %bias.68 : Tensor? = prim::GetAttr[name="bias"](%_0.28)
  %681 : int[] = prim::ListConstruct(%60, %60)
  %682 : int[] = prim::ListConstruct(%68, %68)
  %683 : int[] = prim::ListConstruct(%60, %60)
  %input0.31 : Tensor = aten::conv2d(%input3.1, %weight.68, %bias.68, %681, %682, %683, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.67 : bool = prim::GetAttr[name="training"](%_1.28)
   = prim::If(%training.67) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.35 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.28)
      %687 : Tensor = aten::add_(%num_batches_tracked.35, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.69 : bool = prim::GetAttr[name="training"](%_1.28)
  %running_mean.35 : Tensor = prim::GetAttr[name="running_mean"](%_1.28)
  %running_var.35 : Tensor = prim::GetAttr[name="running_var"](%_1.28)
  %weight.70 : Tensor = prim::GetAttr[name="weight"](%_1.28)
  %bias.70 : Tensor = prim::GetAttr[name="bias"](%_1.28)
   = prim::If(%training.69) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %693 : int[] = aten::size(%input0.31) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.35 : int = aten::__getitem__(%693, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %695 : int = aten::len(%693) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %696 : int = aten::sub(%695, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.71 : int = prim::Loop(%696, %67, %size_prods.35) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.35 : int, %size_prods0.73 : int):
          %700 : int = aten::add(%i.35, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %701 : int = aten::__getitem__(%693, %700) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.35 : int = aten::mul(%size_prods0.73, %701) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.35)
      %703 : bool = aten::eq(%size_prods0.71, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%703) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %704 : str = aten::format(%65, %693) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%704, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.23 : Tensor = aten::batch_norm(%input0.31, %weight.70, %bias.70, %running_mean.35, %running_var.35, %training.69, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out.10 : Tensor = aten::gelu(%input1.23, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %depthwise_conv.10 : __torch__.torch.nn.modules.container.___torch_mangle_4.Sequential = prim::GetAttr[name="depthwise_conv"](%_4)
  %_0.30 : __torch__.torch.nn.modules.conv.___torch_mangle_3.Conv2d = prim::GetAttr[name="0"](%depthwise_conv.10)
  %_1.30 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="1"](%depthwise_conv.10)
  %weight.72 : Tensor = prim::GetAttr[name="weight"](%_0.30)
  %bias.72 : Tensor? = prim::GetAttr[name="bias"](%_0.30)
  %712 : int[] = prim::ListConstruct(%60, %60)
  %713 : int[] = prim::ListConstruct(%60, %60)
  %714 : int[] = prim::ListConstruct(%60, %60)
  %input0.33 : Tensor = aten::conv2d(%out.10, %weight.72, %bias.72, %712, %713, %714, %69) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.71 : bool = prim::GetAttr[name="training"](%_1.30)
   = prim::If(%training.71) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.37 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.30)
      %718 : Tensor = aten::add_(%num_batches_tracked.37, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.73 : bool = prim::GetAttr[name="training"](%_1.30)
  %running_mean.37 : Tensor = prim::GetAttr[name="running_mean"](%_1.30)
  %running_var.37 : Tensor = prim::GetAttr[name="running_var"](%_1.30)
  %weight.74 : Tensor = prim::GetAttr[name="weight"](%_1.30)
  %bias.74 : Tensor = prim::GetAttr[name="bias"](%_1.30)
   = prim::If(%training.73) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %724 : int[] = aten::size(%input0.33) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.37 : int = aten::__getitem__(%724, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %726 : int = aten::len(%724) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %727 : int = aten::sub(%726, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.75 : int = prim::Loop(%727, %67, %size_prods.37) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.37 : int, %size_prods0.77 : int):
          %731 : int = aten::add(%i.37, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %732 : int = aten::__getitem__(%724, %731) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.37 : int = aten::mul(%size_prods0.77, %732) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.37)
      %734 : bool = aten::eq(%size_prods0.75, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%734) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %735 : str = aten::format(%65, %724) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%735, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.25 : Tensor = aten::batch_norm(%input0.33, %weight.74, %bias.74, %running_mean.37, %running_var.37, %training.73, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out0.10 : Tensor = aten::gelu(%input1.25, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %srm.10 : __torch__.SRMLayer = prim::GetAttr[name="srm"](%_4)
  %739 : int[] = aten::size(%out0.10) # /home/auto_update_valid_train.py:179:21
  %b.10 : int, %c.10 : int, %742 : int, %743 : int = prim::ListUnpack(%739)
  %744 : int[] = prim::ListConstruct(%b.10, %c.10, %70)
  %745 : Tensor = aten::view(%out0.10, %744) # /home/auto_update_valid_train.py:182:15
  %746 : int[] = prim::ListConstruct(%70)
  %747 : Tensor = aten::mean(%745, %746, %71, %72) # /home/auto_update_valid_train.py:182:15
  %mean.10 : Tensor = aten::unsqueeze(%747, %70) # /home/auto_update_valid_train.py:182:15
  %749 : int[] = prim::ListConstruct(%b.10, %c.10, %70)
  %750 : Tensor = aten::view(%out0.10, %749) # /home/auto_update_valid_train.py:183:14
  %751 : int[] = prim::ListConstruct(%70)
  %752 : Tensor = aten::std(%750, %751, %67, %71) # /home/auto_update_valid_train.py:183:14
  %std.10 : Tensor = aten::unsqueeze(%752, %70) # /home/auto_update_valid_train.py:183:14
  %754 : Tensor[] = prim::ListConstruct(%mean.10, %std.10)
  %u.10 : Tensor = aten::cat(%754, %70) # /home/auto_update_valid_train.py:184:12
  %cfc.10 : __torch__.torch.nn.modules.conv.Conv1d = prim::GetAttr[name="cfc"](%srm.10)
  %weight.76 : Tensor = prim::GetAttr[name="weight"](%cfc.10)
  %bias.76 : Tensor? = prim::GetAttr[name="bias"](%cfc.10)
  %759 : int[] = prim::ListConstruct(%60)
  %760 : int[] = prim::ListConstruct(%68)
  %761 : int[] = prim::ListConstruct(%60)
  %z.10 : Tensor = aten::conv1d(%u.10, %weight.76, %bias.76, %759, %760, %761, %69) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:370:15
  %bn.10 : __torch__.torch.nn.modules.batchnorm.BatchNorm1d = prim::GetAttr[name="bn"](%srm.10)
  %training.75 : bool = prim::GetAttr[name="training"](%bn.10)
   = prim::If(%training.75) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.39 : Tensor = prim::GetAttr[name="num_batches_tracked"](%bn.10)
      %766 : Tensor = aten::add_(%num_batches_tracked.39, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.77 : bool = prim::GetAttr[name="training"](%bn.10)
  %running_mean.39 : Tensor = prim::GetAttr[name="running_mean"](%bn.10)
  %running_var.39 : Tensor = prim::GetAttr[name="running_var"](%bn.10)
  %weight.78 : Tensor = prim::GetAttr[name="weight"](%bn.10)
  %bias.78 : Tensor = prim::GetAttr[name="bias"](%bn.10)
   = prim::If(%training.77) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %772 : int[] = aten::size(%z.10) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.39 : int = aten::__getitem__(%772, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %774 : int = aten::len(%772) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %775 : int = aten::sub(%774, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.79 : int = prim::Loop(%775, %67, %size_prods.39) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.39 : int, %size_prods0.81 : int):
          %779 : int = aten::add(%i.39, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %780 : int = aten::__getitem__(%772, %779) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.39 : int = aten::mul(%size_prods0.81, %780) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.39)
      %782 : bool = aten::eq(%size_prods0.79, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%782) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %783 : str = aten::format(%65, %772) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%783, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %z0.10 : Tensor = aten::batch_norm(%z.10, %weight.78, %bias.78, %running_mean.39, %running_var.39, %training.77, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %g.10 : Tensor = aten::sigmoid(%z0.10) # /home/auto_update_valid_train.py:189:12
  %786 : int[] = prim::ListConstruct(%b.10, %c.10, %60, %60)
  %g0.10 : Tensor = aten::view(%g.10, %786) # /home/auto_update_valid_train.py:190:12
  %788 : Tensor = aten::expand_as(%g0.10, %out0.10) # /home/auto_update_valid_train.py:192:19
  %out1.10 : Tensor = aten::mul(%out0.10, %788) # /home/auto_update_valid_train.py:192:15
  %project_conv.10 : __torch__.torch.nn.modules.container.___torch_mangle_6.Sequential = prim::GetAttr[name="project_conv"](%_4)
  %_0.32 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="0"](%project_conv.10)
  %_1.32 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="1"](%project_conv.10)
  %weight.80 : Tensor = prim::GetAttr[name="weight"](%_0.32)
  %bias.80 : Tensor? = prim::GetAttr[name="bias"](%_0.32)
  %795 : int[] = prim::ListConstruct(%60, %60)
  %796 : int[] = prim::ListConstruct(%68, %68)
  %797 : int[] = prim::ListConstruct(%60, %60)
  %input0.35 : Tensor = aten::conv2d(%out1.10, %weight.80, %bias.80, %795, %796, %797, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.79 : bool = prim::GetAttr[name="training"](%_1.32)
   = prim::If(%training.79) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.41 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.32)
      %801 : Tensor = aten::add_(%num_batches_tracked.41, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.81 : bool = prim::GetAttr[name="training"](%_1.32)
  %running_mean.41 : Tensor = prim::GetAttr[name="running_mean"](%_1.32)
  %running_var.41 : Tensor = prim::GetAttr[name="running_var"](%_1.32)
  %weight.82 : Tensor = prim::GetAttr[name="weight"](%_1.32)
  %bias.82 : Tensor = prim::GetAttr[name="bias"](%_1.32)
   = prim::If(%training.81) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %807 : int[] = aten::size(%input0.35) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.41 : int = aten::__getitem__(%807, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %809 : int = aten::len(%807) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %810 : int = aten::sub(%809, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.83 : int = prim::Loop(%810, %67, %size_prods.41) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.41 : int, %size_prods0.85 : int):
          %814 : int = aten::add(%i.41, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %815 : int = aten::__getitem__(%807, %814) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.41 : int = aten::mul(%size_prods0.85, %815) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.41)
      %817 : bool = aten::eq(%size_prods0.83, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%817) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %818 : str = aten::format(%65, %807) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%818, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out2.10 : Tensor = aten::batch_norm(%input0.35, %weight.82, %bias.82, %running_mean.41, %running_var.41, %training.81, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %use_residual.10 : bool = prim::GetAttr[name="use_residual"](%_4)
  %input4.1 : Tensor = prim::If(%use_residual.10) # /home/auto_update_valid_train.py:261:8
    block0():
      %out3.10 : Tensor = aten::add(%out2.10, %input3.1, %60) # /home/auto_update_valid_train.py:263:18
      -> (%out3.10)
    block1():
      -> (%out2.10)
  %expand_conv.12 : __torch__.torch.nn.modules.container.___torch_mangle_2.Sequential = prim::GetAttr[name="expand_conv"](%_5)
  %_0.34 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="0"](%expand_conv.12)
  %_1.34 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="1"](%expand_conv.12)
  %weight.84 : Tensor = prim::GetAttr[name="weight"](%_0.34)
  %bias.84 : Tensor? = prim::GetAttr[name="bias"](%_0.34)
  %828 : int[] = prim::ListConstruct(%60, %60)
  %829 : int[] = prim::ListConstruct(%68, %68)
  %830 : int[] = prim::ListConstruct(%60, %60)
  %input0.37 : Tensor = aten::conv2d(%input4.1, %weight.84, %bias.84, %828, %829, %830, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.83 : bool = prim::GetAttr[name="training"](%_1.34)
   = prim::If(%training.83) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.43 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.34)
      %834 : Tensor = aten::add_(%num_batches_tracked.43, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.85 : bool = prim::GetAttr[name="training"](%_1.34)
  %running_mean.43 : Tensor = prim::GetAttr[name="running_mean"](%_1.34)
  %running_var.43 : Tensor = prim::GetAttr[name="running_var"](%_1.34)
  %weight.86 : Tensor = prim::GetAttr[name="weight"](%_1.34)
  %bias.86 : Tensor = prim::GetAttr[name="bias"](%_1.34)
   = prim::If(%training.85) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %840 : int[] = aten::size(%input0.37) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.43 : int = aten::__getitem__(%840, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %842 : int = aten::len(%840) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %843 : int = aten::sub(%842, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.87 : int = prim::Loop(%843, %67, %size_prods.43) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.43 : int, %size_prods0.89 : int):
          %847 : int = aten::add(%i.43, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %848 : int = aten::__getitem__(%840, %847) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.43 : int = aten::mul(%size_prods0.89, %848) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.43)
      %850 : bool = aten::eq(%size_prods0.87, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%850) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %851 : str = aten::format(%65, %840) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%851, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.27 : Tensor = aten::batch_norm(%input0.37, %weight.86, %bias.86, %running_mean.43, %running_var.43, %training.85, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out.12 : Tensor = aten::gelu(%input1.27, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %depthwise_conv.12 : __torch__.torch.nn.modules.container.___torch_mangle_4.Sequential = prim::GetAttr[name="depthwise_conv"](%_5)
  %_0.36 : __torch__.torch.nn.modules.conv.___torch_mangle_3.Conv2d = prim::GetAttr[name="0"](%depthwise_conv.12)
  %_1.36 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="1"](%depthwise_conv.12)
  %weight.88 : Tensor = prim::GetAttr[name="weight"](%_0.36)
  %bias.88 : Tensor? = prim::GetAttr[name="bias"](%_0.36)
  %859 : int[] = prim::ListConstruct(%60, %60)
  %860 : int[] = prim::ListConstruct(%60, %60)
  %861 : int[] = prim::ListConstruct(%60, %60)
  %input0.39 : Tensor = aten::conv2d(%out.12, %weight.88, %bias.88, %859, %860, %861, %69) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.87 : bool = prim::GetAttr[name="training"](%_1.36)
   = prim::If(%training.87) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.45 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.36)
      %865 : Tensor = aten::add_(%num_batches_tracked.45, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.89 : bool = prim::GetAttr[name="training"](%_1.36)
  %running_mean.45 : Tensor = prim::GetAttr[name="running_mean"](%_1.36)
  %running_var.45 : Tensor = prim::GetAttr[name="running_var"](%_1.36)
  %weight.90 : Tensor = prim::GetAttr[name="weight"](%_1.36)
  %bias.90 : Tensor = prim::GetAttr[name="bias"](%_1.36)
   = prim::If(%training.89) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %871 : int[] = aten::size(%input0.39) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.45 : int = aten::__getitem__(%871, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %873 : int = aten::len(%871) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %874 : int = aten::sub(%873, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.91 : int = prim::Loop(%874, %67, %size_prods.45) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.45 : int, %size_prods0.93 : int):
          %878 : int = aten::add(%i.45, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %879 : int = aten::__getitem__(%871, %878) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.45 : int = aten::mul(%size_prods0.93, %879) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.45)
      %881 : bool = aten::eq(%size_prods0.91, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%881) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %882 : str = aten::format(%65, %871) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%882, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.29 : Tensor = aten::batch_norm(%input0.39, %weight.90, %bias.90, %running_mean.45, %running_var.45, %training.89, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out0.12 : Tensor = aten::gelu(%input1.29, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %srm.12 : __torch__.SRMLayer = prim::GetAttr[name="srm"](%_5)
  %886 : int[] = aten::size(%out0.12) # /home/auto_update_valid_train.py:179:21
  %b.12 : int, %c.12 : int, %889 : int, %890 : int = prim::ListUnpack(%886)
  %891 : int[] = prim::ListConstruct(%b.12, %c.12, %70)
  %892 : Tensor = aten::view(%out0.12, %891) # /home/auto_update_valid_train.py:182:15
  %893 : int[] = prim::ListConstruct(%70)
  %894 : Tensor = aten::mean(%892, %893, %71, %72) # /home/auto_update_valid_train.py:182:15
  %mean.12 : Tensor = aten::unsqueeze(%894, %70) # /home/auto_update_valid_train.py:182:15
  %896 : int[] = prim::ListConstruct(%b.12, %c.12, %70)
  %897 : Tensor = aten::view(%out0.12, %896) # /home/auto_update_valid_train.py:183:14
  %898 : int[] = prim::ListConstruct(%70)
  %899 : Tensor = aten::std(%897, %898, %67, %71) # /home/auto_update_valid_train.py:183:14
  %std.12 : Tensor = aten::unsqueeze(%899, %70) # /home/auto_update_valid_train.py:183:14
  %901 : Tensor[] = prim::ListConstruct(%mean.12, %std.12)
  %u.12 : Tensor = aten::cat(%901, %70) # /home/auto_update_valid_train.py:184:12
  %cfc.12 : __torch__.torch.nn.modules.conv.Conv1d = prim::GetAttr[name="cfc"](%srm.12)
  %weight.92 : Tensor = prim::GetAttr[name="weight"](%cfc.12)
  %bias.92 : Tensor? = prim::GetAttr[name="bias"](%cfc.12)
  %906 : int[] = prim::ListConstruct(%60)
  %907 : int[] = prim::ListConstruct(%68)
  %908 : int[] = prim::ListConstruct(%60)
  %z.12 : Tensor = aten::conv1d(%u.12, %weight.92, %bias.92, %906, %907, %908, %69) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:370:15
  %bn.12 : __torch__.torch.nn.modules.batchnorm.BatchNorm1d = prim::GetAttr[name="bn"](%srm.12)
  %training.91 : bool = prim::GetAttr[name="training"](%bn.12)
   = prim::If(%training.91) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.47 : Tensor = prim::GetAttr[name="num_batches_tracked"](%bn.12)
      %913 : Tensor = aten::add_(%num_batches_tracked.47, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.93 : bool = prim::GetAttr[name="training"](%bn.12)
  %running_mean.47 : Tensor = prim::GetAttr[name="running_mean"](%bn.12)
  %running_var.47 : Tensor = prim::GetAttr[name="running_var"](%bn.12)
  %weight.94 : Tensor = prim::GetAttr[name="weight"](%bn.12)
  %bias.94 : Tensor = prim::GetAttr[name="bias"](%bn.12)
   = prim::If(%training.93) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %919 : int[] = aten::size(%z.12) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.47 : int = aten::__getitem__(%919, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %921 : int = aten::len(%919) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %922 : int = aten::sub(%921, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.95 : int = prim::Loop(%922, %67, %size_prods.47) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.47 : int, %size_prods0.97 : int):
          %926 : int = aten::add(%i.47, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %927 : int = aten::__getitem__(%919, %926) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.47 : int = aten::mul(%size_prods0.97, %927) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.47)
      %929 : bool = aten::eq(%size_prods0.95, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%929) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %930 : str = aten::format(%65, %919) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%930, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %z0.12 : Tensor = aten::batch_norm(%z.12, %weight.94, %bias.94, %running_mean.47, %running_var.47, %training.93, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %g.12 : Tensor = aten::sigmoid(%z0.12) # /home/auto_update_valid_train.py:189:12
  %933 : int[] = prim::ListConstruct(%b.12, %c.12, %60, %60)
  %g0.12 : Tensor = aten::view(%g.12, %933) # /home/auto_update_valid_train.py:190:12
  %935 : Tensor = aten::expand_as(%g0.12, %out0.12) # /home/auto_update_valid_train.py:192:19
  %out1.12 : Tensor = aten::mul(%out0.12, %935) # /home/auto_update_valid_train.py:192:15
  %project_conv.12 : __torch__.torch.nn.modules.container.___torch_mangle_6.Sequential = prim::GetAttr[name="project_conv"](%_5)
  %_0.38 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="0"](%project_conv.12)
  %_1.38 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="1"](%project_conv.12)
  %weight.96 : Tensor = prim::GetAttr[name="weight"](%_0.38)
  %bias.96 : Tensor? = prim::GetAttr[name="bias"](%_0.38)
  %942 : int[] = prim::ListConstruct(%60, %60)
  %943 : int[] = prim::ListConstruct(%68, %68)
  %944 : int[] = prim::ListConstruct(%60, %60)
  %input0.41 : Tensor = aten::conv2d(%out1.12, %weight.96, %bias.96, %942, %943, %944, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.95 : bool = prim::GetAttr[name="training"](%_1.38)
   = prim::If(%training.95) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.49 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.38)
      %948 : Tensor = aten::add_(%num_batches_tracked.49, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.97 : bool = prim::GetAttr[name="training"](%_1.38)
  %running_mean.49 : Tensor = prim::GetAttr[name="running_mean"](%_1.38)
  %running_var.49 : Tensor = prim::GetAttr[name="running_var"](%_1.38)
  %weight.98 : Tensor = prim::GetAttr[name="weight"](%_1.38)
  %bias.98 : Tensor = prim::GetAttr[name="bias"](%_1.38)
   = prim::If(%training.97) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %954 : int[] = aten::size(%input0.41) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.49 : int = aten::__getitem__(%954, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %956 : int = aten::len(%954) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %957 : int = aten::sub(%956, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.99 : int = prim::Loop(%957, %67, %size_prods.49) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.49 : int, %size_prods0.101 : int):
          %961 : int = aten::add(%i.49, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %962 : int = aten::__getitem__(%954, %961) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.49 : int = aten::mul(%size_prods0.101, %962) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.49)
      %964 : bool = aten::eq(%size_prods0.99, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%964) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %965 : str = aten::format(%65, %954) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%965, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out2.12 : Tensor = aten::batch_norm(%input0.41, %weight.98, %bias.98, %running_mean.49, %running_var.49, %training.97, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %use_residual.12 : bool = prim::GetAttr[name="use_residual"](%_5)
  %input5.1 : Tensor = prim::If(%use_residual.12) # /home/auto_update_valid_train.py:261:8
    block0():
      %out3.12 : Tensor = aten::add(%out2.12, %input4.1, %60) # /home/auto_update_valid_train.py:263:18
      -> (%out3.12)
    block1():
      -> (%out2.12)
  %expand_conv.14 : __torch__.torch.nn.modules.container.___torch_mangle_2.Sequential = prim::GetAttr[name="expand_conv"](%_6)
  %_0.40 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="0"](%expand_conv.14)
  %_1.40 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="1"](%expand_conv.14)
  %weight.100 : Tensor = prim::GetAttr[name="weight"](%_0.40)
  %bias.100 : Tensor? = prim::GetAttr[name="bias"](%_0.40)
  %975 : int[] = prim::ListConstruct(%60, %60)
  %976 : int[] = prim::ListConstruct(%68, %68)
  %977 : int[] = prim::ListConstruct(%60, %60)
  %input0.43 : Tensor = aten::conv2d(%input5.1, %weight.100, %bias.100, %975, %976, %977, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.99 : bool = prim::GetAttr[name="training"](%_1.40)
   = prim::If(%training.99) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.51 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.40)
      %981 : Tensor = aten::add_(%num_batches_tracked.51, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.101 : bool = prim::GetAttr[name="training"](%_1.40)
  %running_mean.51 : Tensor = prim::GetAttr[name="running_mean"](%_1.40)
  %running_var.51 : Tensor = prim::GetAttr[name="running_var"](%_1.40)
  %weight.102 : Tensor = prim::GetAttr[name="weight"](%_1.40)
  %bias.102 : Tensor = prim::GetAttr[name="bias"](%_1.40)
   = prim::If(%training.101) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %987 : int[] = aten::size(%input0.43) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.51 : int = aten::__getitem__(%987, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %989 : int = aten::len(%987) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %990 : int = aten::sub(%989, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.103 : int = prim::Loop(%990, %67, %size_prods.51) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.51 : int, %size_prods0.105 : int):
          %994 : int = aten::add(%i.51, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %995 : int = aten::__getitem__(%987, %994) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.51 : int = aten::mul(%size_prods0.105, %995) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.51)
      %997 : bool = aten::eq(%size_prods0.103, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%997) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %998 : str = aten::format(%65, %987) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%998, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.31 : Tensor = aten::batch_norm(%input0.43, %weight.102, %bias.102, %running_mean.51, %running_var.51, %training.101, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out.14 : Tensor = aten::gelu(%input1.31, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %depthwise_conv.14 : __torch__.torch.nn.modules.container.___torch_mangle_4.Sequential = prim::GetAttr[name="depthwise_conv"](%_6)
  %_0.42 : __torch__.torch.nn.modules.conv.___torch_mangle_3.Conv2d = prim::GetAttr[name="0"](%depthwise_conv.14)
  %_1.42 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="1"](%depthwise_conv.14)
  %weight.104 : Tensor = prim::GetAttr[name="weight"](%_0.42)
  %bias.104 : Tensor? = prim::GetAttr[name="bias"](%_0.42)
  %1006 : int[] = prim::ListConstruct(%60, %60)
  %1007 : int[] = prim::ListConstruct(%60, %60)
  %1008 : int[] = prim::ListConstruct(%60, %60)
  %input0.45 : Tensor = aten::conv2d(%out.14, %weight.104, %bias.104, %1006, %1007, %1008, %69) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.103 : bool = prim::GetAttr[name="training"](%_1.42)
   = prim::If(%training.103) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.53 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.42)
      %1012 : Tensor = aten::add_(%num_batches_tracked.53, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.105 : bool = prim::GetAttr[name="training"](%_1.42)
  %running_mean.53 : Tensor = prim::GetAttr[name="running_mean"](%_1.42)
  %running_var.53 : Tensor = prim::GetAttr[name="running_var"](%_1.42)
  %weight.106 : Tensor = prim::GetAttr[name="weight"](%_1.42)
  %bias.106 : Tensor = prim::GetAttr[name="bias"](%_1.42)
   = prim::If(%training.105) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1018 : int[] = aten::size(%input0.45) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.53 : int = aten::__getitem__(%1018, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1020 : int = aten::len(%1018) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1021 : int = aten::sub(%1020, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.107 : int = prim::Loop(%1021, %67, %size_prods.53) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.53 : int, %size_prods0.109 : int):
          %1025 : int = aten::add(%i.53, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1026 : int = aten::__getitem__(%1018, %1025) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.53 : int = aten::mul(%size_prods0.109, %1026) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.53)
      %1028 : bool = aten::eq(%size_prods0.107, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1028) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1029 : str = aten::format(%65, %1018) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1029, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.33 : Tensor = aten::batch_norm(%input0.45, %weight.106, %bias.106, %running_mean.53, %running_var.53, %training.105, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out0.14 : Tensor = aten::gelu(%input1.33, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %srm.14 : __torch__.SRMLayer = prim::GetAttr[name="srm"](%_6)
  %1033 : int[] = aten::size(%out0.14) # /home/auto_update_valid_train.py:179:21
  %b.14 : int, %c.14 : int, %1036 : int, %1037 : int = prim::ListUnpack(%1033)
  %1038 : int[] = prim::ListConstruct(%b.14, %c.14, %70)
  %1039 : Tensor = aten::view(%out0.14, %1038) # /home/auto_update_valid_train.py:182:15
  %1040 : int[] = prim::ListConstruct(%70)
  %1041 : Tensor = aten::mean(%1039, %1040, %71, %72) # /home/auto_update_valid_train.py:182:15
  %mean.14 : Tensor = aten::unsqueeze(%1041, %70) # /home/auto_update_valid_train.py:182:15
  %1043 : int[] = prim::ListConstruct(%b.14, %c.14, %70)
  %1044 : Tensor = aten::view(%out0.14, %1043) # /home/auto_update_valid_train.py:183:14
  %1045 : int[] = prim::ListConstruct(%70)
  %1046 : Tensor = aten::std(%1044, %1045, %67, %71) # /home/auto_update_valid_train.py:183:14
  %std.14 : Tensor = aten::unsqueeze(%1046, %70) # /home/auto_update_valid_train.py:183:14
  %1048 : Tensor[] = prim::ListConstruct(%mean.14, %std.14)
  %u.14 : Tensor = aten::cat(%1048, %70) # /home/auto_update_valid_train.py:184:12
  %cfc.14 : __torch__.torch.nn.modules.conv.Conv1d = prim::GetAttr[name="cfc"](%srm.14)
  %weight.108 : Tensor = prim::GetAttr[name="weight"](%cfc.14)
  %bias.108 : Tensor? = prim::GetAttr[name="bias"](%cfc.14)
  %1053 : int[] = prim::ListConstruct(%60)
  %1054 : int[] = prim::ListConstruct(%68)
  %1055 : int[] = prim::ListConstruct(%60)
  %z.14 : Tensor = aten::conv1d(%u.14, %weight.108, %bias.108, %1053, %1054, %1055, %69) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:370:15
  %bn.14 : __torch__.torch.nn.modules.batchnorm.BatchNorm1d = prim::GetAttr[name="bn"](%srm.14)
  %training.107 : bool = prim::GetAttr[name="training"](%bn.14)
   = prim::If(%training.107) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.55 : Tensor = prim::GetAttr[name="num_batches_tracked"](%bn.14)
      %1060 : Tensor = aten::add_(%num_batches_tracked.55, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.109 : bool = prim::GetAttr[name="training"](%bn.14)
  %running_mean.55 : Tensor = prim::GetAttr[name="running_mean"](%bn.14)
  %running_var.55 : Tensor = prim::GetAttr[name="running_var"](%bn.14)
  %weight.110 : Tensor = prim::GetAttr[name="weight"](%bn.14)
  %bias.110 : Tensor = prim::GetAttr[name="bias"](%bn.14)
   = prim::If(%training.109) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1066 : int[] = aten::size(%z.14) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.55 : int = aten::__getitem__(%1066, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1068 : int = aten::len(%1066) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1069 : int = aten::sub(%1068, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.111 : int = prim::Loop(%1069, %67, %size_prods.55) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.55 : int, %size_prods0.113 : int):
          %1073 : int = aten::add(%i.55, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1074 : int = aten::__getitem__(%1066, %1073) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.55 : int = aten::mul(%size_prods0.113, %1074) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.55)
      %1076 : bool = aten::eq(%size_prods0.111, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1076) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1077 : str = aten::format(%65, %1066) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1077, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %z0.14 : Tensor = aten::batch_norm(%z.14, %weight.110, %bias.110, %running_mean.55, %running_var.55, %training.109, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %g.14 : Tensor = aten::sigmoid(%z0.14) # /home/auto_update_valid_train.py:189:12
  %1080 : int[] = prim::ListConstruct(%b.14, %c.14, %60, %60)
  %g0.14 : Tensor = aten::view(%g.14, %1080) # /home/auto_update_valid_train.py:190:12
  %1082 : Tensor = aten::expand_as(%g0.14, %out0.14) # /home/auto_update_valid_train.py:192:19
  %out1.14 : Tensor = aten::mul(%out0.14, %1082) # /home/auto_update_valid_train.py:192:15
  %project_conv.14 : __torch__.torch.nn.modules.container.___torch_mangle_6.Sequential = prim::GetAttr[name="project_conv"](%_6)
  %_0.44 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="0"](%project_conv.14)
  %_1.44 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="1"](%project_conv.14)
  %weight.112 : Tensor = prim::GetAttr[name="weight"](%_0.44)
  %bias.112 : Tensor? = prim::GetAttr[name="bias"](%_0.44)
  %1089 : int[] = prim::ListConstruct(%60, %60)
  %1090 : int[] = prim::ListConstruct(%68, %68)
  %1091 : int[] = prim::ListConstruct(%60, %60)
  %input0.47 : Tensor = aten::conv2d(%out1.14, %weight.112, %bias.112, %1089, %1090, %1091, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.111 : bool = prim::GetAttr[name="training"](%_1.44)
   = prim::If(%training.111) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.57 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.44)
      %1095 : Tensor = aten::add_(%num_batches_tracked.57, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.113 : bool = prim::GetAttr[name="training"](%_1.44)
  %running_mean.57 : Tensor = prim::GetAttr[name="running_mean"](%_1.44)
  %running_var.57 : Tensor = prim::GetAttr[name="running_var"](%_1.44)
  %weight.114 : Tensor = prim::GetAttr[name="weight"](%_1.44)
  %bias.114 : Tensor = prim::GetAttr[name="bias"](%_1.44)
   = prim::If(%training.113) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1101 : int[] = aten::size(%input0.47) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.57 : int = aten::__getitem__(%1101, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1103 : int = aten::len(%1101) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1104 : int = aten::sub(%1103, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.115 : int = prim::Loop(%1104, %67, %size_prods.57) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.57 : int, %size_prods0.117 : int):
          %1108 : int = aten::add(%i.57, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1109 : int = aten::__getitem__(%1101, %1108) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.57 : int = aten::mul(%size_prods0.117, %1109) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.57)
      %1111 : bool = aten::eq(%size_prods0.115, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1111) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1112 : str = aten::format(%65, %1101) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1112, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out2.14 : Tensor = aten::batch_norm(%input0.47, %weight.114, %bias.114, %running_mean.57, %running_var.57, %training.113, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %use_residual.14 : bool = prim::GetAttr[name="use_residual"](%_6)
  %input6.1 : Tensor = prim::If(%use_residual.14) # /home/auto_update_valid_train.py:261:8
    block0():
      %out3.14 : Tensor = aten::add(%out2.14, %input5.1, %60) # /home/auto_update_valid_train.py:263:18
      -> (%out3.14)
    block1():
      -> (%out2.14)
  %expand_conv.16 : __torch__.torch.nn.modules.container.___torch_mangle_2.Sequential = prim::GetAttr[name="expand_conv"](%_7)
  %_0.46 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="0"](%expand_conv.16)
  %_1.46 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="1"](%expand_conv.16)
  %weight.116 : Tensor = prim::GetAttr[name="weight"](%_0.46)
  %bias.116 : Tensor? = prim::GetAttr[name="bias"](%_0.46)
  %1122 : int[] = prim::ListConstruct(%60, %60)
  %1123 : int[] = prim::ListConstruct(%68, %68)
  %1124 : int[] = prim::ListConstruct(%60, %60)
  %input0.49 : Tensor = aten::conv2d(%input6.1, %weight.116, %bias.116, %1122, %1123, %1124, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.115 : bool = prim::GetAttr[name="training"](%_1.46)
   = prim::If(%training.115) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.59 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.46)
      %1128 : Tensor = aten::add_(%num_batches_tracked.59, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.117 : bool = prim::GetAttr[name="training"](%_1.46)
  %running_mean.59 : Tensor = prim::GetAttr[name="running_mean"](%_1.46)
  %running_var.59 : Tensor = prim::GetAttr[name="running_var"](%_1.46)
  %weight.118 : Tensor = prim::GetAttr[name="weight"](%_1.46)
  %bias.118 : Tensor = prim::GetAttr[name="bias"](%_1.46)
   = prim::If(%training.117) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1134 : int[] = aten::size(%input0.49) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.59 : int = aten::__getitem__(%1134, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1136 : int = aten::len(%1134) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1137 : int = aten::sub(%1136, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.119 : int = prim::Loop(%1137, %67, %size_prods.59) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.59 : int, %size_prods0.121 : int):
          %1141 : int = aten::add(%i.59, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1142 : int = aten::__getitem__(%1134, %1141) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.59 : int = aten::mul(%size_prods0.121, %1142) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.59)
      %1144 : bool = aten::eq(%size_prods0.119, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1144) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1145 : str = aten::format(%65, %1134) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1145, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.35 : Tensor = aten::batch_norm(%input0.49, %weight.118, %bias.118, %running_mean.59, %running_var.59, %training.117, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out.16 : Tensor = aten::gelu(%input1.35, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %depthwise_conv.16 : __torch__.torch.nn.modules.container.___torch_mangle_4.Sequential = prim::GetAttr[name="depthwise_conv"](%_7)
  %_0.48 : __torch__.torch.nn.modules.conv.___torch_mangle_3.Conv2d = prim::GetAttr[name="0"](%depthwise_conv.16)
  %_1.48 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="1"](%depthwise_conv.16)
  %weight.120 : Tensor = prim::GetAttr[name="weight"](%_0.48)
  %bias.120 : Tensor? = prim::GetAttr[name="bias"](%_0.48)
  %1153 : int[] = prim::ListConstruct(%60, %60)
  %1154 : int[] = prim::ListConstruct(%60, %60)
  %1155 : int[] = prim::ListConstruct(%60, %60)
  %input0.51 : Tensor = aten::conv2d(%out.16, %weight.120, %bias.120, %1153, %1154, %1155, %69) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.119 : bool = prim::GetAttr[name="training"](%_1.48)
   = prim::If(%training.119) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.61 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.48)
      %1159 : Tensor = aten::add_(%num_batches_tracked.61, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.121 : bool = prim::GetAttr[name="training"](%_1.48)
  %running_mean.61 : Tensor = prim::GetAttr[name="running_mean"](%_1.48)
  %running_var.61 : Tensor = prim::GetAttr[name="running_var"](%_1.48)
  %weight.122 : Tensor = prim::GetAttr[name="weight"](%_1.48)
  %bias.122 : Tensor = prim::GetAttr[name="bias"](%_1.48)
   = prim::If(%training.121) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1165 : int[] = aten::size(%input0.51) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.61 : int = aten::__getitem__(%1165, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1167 : int = aten::len(%1165) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1168 : int = aten::sub(%1167, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.123 : int = prim::Loop(%1168, %67, %size_prods.61) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.61 : int, %size_prods0.125 : int):
          %1172 : int = aten::add(%i.61, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1173 : int = aten::__getitem__(%1165, %1172) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.61 : int = aten::mul(%size_prods0.125, %1173) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.61)
      %1175 : bool = aten::eq(%size_prods0.123, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1175) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1176 : str = aten::format(%65, %1165) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1176, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.37 : Tensor = aten::batch_norm(%input0.51, %weight.122, %bias.122, %running_mean.61, %running_var.61, %training.121, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out0.16 : Tensor = aten::gelu(%input1.37, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %srm.16 : __torch__.SRMLayer = prim::GetAttr[name="srm"](%_7)
  %1180 : int[] = aten::size(%out0.16) # /home/auto_update_valid_train.py:179:21
  %b.16 : int, %c.16 : int, %1183 : int, %1184 : int = prim::ListUnpack(%1180)
  %1185 : int[] = prim::ListConstruct(%b.16, %c.16, %70)
  %1186 : Tensor = aten::view(%out0.16, %1185) # /home/auto_update_valid_train.py:182:15
  %1187 : int[] = prim::ListConstruct(%70)
  %1188 : Tensor = aten::mean(%1186, %1187, %71, %72) # /home/auto_update_valid_train.py:182:15
  %mean.16 : Tensor = aten::unsqueeze(%1188, %70) # /home/auto_update_valid_train.py:182:15
  %1190 : int[] = prim::ListConstruct(%b.16, %c.16, %70)
  %1191 : Tensor = aten::view(%out0.16, %1190) # /home/auto_update_valid_train.py:183:14
  %1192 : int[] = prim::ListConstruct(%70)
  %1193 : Tensor = aten::std(%1191, %1192, %67, %71) # /home/auto_update_valid_train.py:183:14
  %std.16 : Tensor = aten::unsqueeze(%1193, %70) # /home/auto_update_valid_train.py:183:14
  %1195 : Tensor[] = prim::ListConstruct(%mean.16, %std.16)
  %u.16 : Tensor = aten::cat(%1195, %70) # /home/auto_update_valid_train.py:184:12
  %cfc.16 : __torch__.torch.nn.modules.conv.Conv1d = prim::GetAttr[name="cfc"](%srm.16)
  %weight.124 : Tensor = prim::GetAttr[name="weight"](%cfc.16)
  %bias.124 : Tensor? = prim::GetAttr[name="bias"](%cfc.16)
  %1200 : int[] = prim::ListConstruct(%60)
  %1201 : int[] = prim::ListConstruct(%68)
  %1202 : int[] = prim::ListConstruct(%60)
  %z.16 : Tensor = aten::conv1d(%u.16, %weight.124, %bias.124, %1200, %1201, %1202, %69) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:370:15
  %bn.16 : __torch__.torch.nn.modules.batchnorm.BatchNorm1d = prim::GetAttr[name="bn"](%srm.16)
  %training.123 : bool = prim::GetAttr[name="training"](%bn.16)
   = prim::If(%training.123) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.63 : Tensor = prim::GetAttr[name="num_batches_tracked"](%bn.16)
      %1207 : Tensor = aten::add_(%num_batches_tracked.63, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.125 : bool = prim::GetAttr[name="training"](%bn.16)
  %running_mean.63 : Tensor = prim::GetAttr[name="running_mean"](%bn.16)
  %running_var.63 : Tensor = prim::GetAttr[name="running_var"](%bn.16)
  %weight.126 : Tensor = prim::GetAttr[name="weight"](%bn.16)
  %bias.126 : Tensor = prim::GetAttr[name="bias"](%bn.16)
   = prim::If(%training.125) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1213 : int[] = aten::size(%z.16) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.63 : int = aten::__getitem__(%1213, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1215 : int = aten::len(%1213) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1216 : int = aten::sub(%1215, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.127 : int = prim::Loop(%1216, %67, %size_prods.63) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.63 : int, %size_prods0.129 : int):
          %1220 : int = aten::add(%i.63, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1221 : int = aten::__getitem__(%1213, %1220) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.63 : int = aten::mul(%size_prods0.129, %1221) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.63)
      %1223 : bool = aten::eq(%size_prods0.127, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1223) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1224 : str = aten::format(%65, %1213) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1224, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %z0.16 : Tensor = aten::batch_norm(%z.16, %weight.126, %bias.126, %running_mean.63, %running_var.63, %training.125, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %g.16 : Tensor = aten::sigmoid(%z0.16) # /home/auto_update_valid_train.py:189:12
  %1227 : int[] = prim::ListConstruct(%b.16, %c.16, %60, %60)
  %g0.16 : Tensor = aten::view(%g.16, %1227) # /home/auto_update_valid_train.py:190:12
  %1229 : Tensor = aten::expand_as(%g0.16, %out0.16) # /home/auto_update_valid_train.py:192:19
  %out1.16 : Tensor = aten::mul(%out0.16, %1229) # /home/auto_update_valid_train.py:192:15
  %project_conv.16 : __torch__.torch.nn.modules.container.___torch_mangle_6.Sequential = prim::GetAttr[name="project_conv"](%_7)
  %_0.50 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="0"](%project_conv.16)
  %_1.50 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="1"](%project_conv.16)
  %weight.128 : Tensor = prim::GetAttr[name="weight"](%_0.50)
  %bias.128 : Tensor? = prim::GetAttr[name="bias"](%_0.50)
  %1236 : int[] = prim::ListConstruct(%60, %60)
  %1237 : int[] = prim::ListConstruct(%68, %68)
  %1238 : int[] = prim::ListConstruct(%60, %60)
  %input0.53 : Tensor = aten::conv2d(%out1.16, %weight.128, %bias.128, %1236, %1237, %1238, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.127 : bool = prim::GetAttr[name="training"](%_1.50)
   = prim::If(%training.127) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.65 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.50)
      %1242 : Tensor = aten::add_(%num_batches_tracked.65, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.129 : bool = prim::GetAttr[name="training"](%_1.50)
  %running_mean.65 : Tensor = prim::GetAttr[name="running_mean"](%_1.50)
  %running_var.65 : Tensor = prim::GetAttr[name="running_var"](%_1.50)
  %weight.130 : Tensor = prim::GetAttr[name="weight"](%_1.50)
  %bias.130 : Tensor = prim::GetAttr[name="bias"](%_1.50)
   = prim::If(%training.129) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1248 : int[] = aten::size(%input0.53) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.65 : int = aten::__getitem__(%1248, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1250 : int = aten::len(%1248) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1251 : int = aten::sub(%1250, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.131 : int = prim::Loop(%1251, %67, %size_prods.65) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.65 : int, %size_prods0.133 : int):
          %1255 : int = aten::add(%i.65, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1256 : int = aten::__getitem__(%1248, %1255) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.65 : int = aten::mul(%size_prods0.133, %1256) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.65)
      %1258 : bool = aten::eq(%size_prods0.131, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1258) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1259 : str = aten::format(%65, %1248) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1259, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out2.16 : Tensor = aten::batch_norm(%input0.53, %weight.130, %bias.130, %running_mean.65, %running_var.65, %training.129, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %use_residual.16 : bool = prim::GetAttr[name="use_residual"](%_7)
  %input7.1 : Tensor = prim::If(%use_residual.16) # /home/auto_update_valid_train.py:261:8
    block0():
      %out3.16 : Tensor = aten::add(%out2.16, %input6.1, %60) # /home/auto_update_valid_train.py:263:18
      -> (%out3.16)
    block1():
      -> (%out2.16)
  %expand_conv.18 : __torch__.torch.nn.modules.container.___torch_mangle_9.Sequential = prim::GetAttr[name="expand_conv"](%_8)
  %_0.52 : __torch__.torch.nn.modules.conv.___torch_mangle_7.Conv2d = prim::GetAttr[name="0"](%expand_conv.18)
  %_1.52 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="1"](%expand_conv.18)
  %weight.132 : Tensor = prim::GetAttr[name="weight"](%_0.52)
  %bias.132 : Tensor? = prim::GetAttr[name="bias"](%_0.52)
  %1269 : int[] = prim::ListConstruct(%60, %60)
  %1270 : int[] = prim::ListConstruct(%68, %68)
  %1271 : int[] = prim::ListConstruct(%60, %60)
  %input0.55 : Tensor = aten::conv2d(%input7.1, %weight.132, %bias.132, %1269, %1270, %1271, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.131 : bool = prim::GetAttr[name="training"](%_1.52)
   = prim::If(%training.131) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.67 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.52)
      %1275 : Tensor = aten::add_(%num_batches_tracked.67, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.133 : bool = prim::GetAttr[name="training"](%_1.52)
  %running_mean.67 : Tensor = prim::GetAttr[name="running_mean"](%_1.52)
  %running_var.67 : Tensor = prim::GetAttr[name="running_var"](%_1.52)
  %weight.134 : Tensor = prim::GetAttr[name="weight"](%_1.52)
  %bias.134 : Tensor = prim::GetAttr[name="bias"](%_1.52)
   = prim::If(%training.133) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1281 : int[] = aten::size(%input0.55) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.67 : int = aten::__getitem__(%1281, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1283 : int = aten::len(%1281) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1284 : int = aten::sub(%1283, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.135 : int = prim::Loop(%1284, %67, %size_prods.67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.67 : int, %size_prods0.137 : int):
          %1288 : int = aten::add(%i.67, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1289 : int = aten::__getitem__(%1281, %1288) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.67 : int = aten::mul(%size_prods0.137, %1289) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.67)
      %1291 : bool = aten::eq(%size_prods0.135, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1291) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1292 : str = aten::format(%65, %1281) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1292, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.39 : Tensor = aten::batch_norm(%input0.55, %weight.134, %bias.134, %running_mean.67, %running_var.67, %training.133, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out.18 : Tensor = aten::gelu(%input1.39, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %depthwise_conv.18 : __torch__.torch.nn.modules.container.___torch_mangle_11.Sequential = prim::GetAttr[name="depthwise_conv"](%_8)
  %_0.54 : __torch__.torch.nn.modules.conv.___torch_mangle_10.Conv2d = prim::GetAttr[name="0"](%depthwise_conv.18)
  %_1.54 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="1"](%depthwise_conv.18)
  %weight.136 : Tensor = prim::GetAttr[name="weight"](%_0.54)
  %bias.136 : Tensor? = prim::GetAttr[name="bias"](%_0.54)
  %1300 : int[] = prim::ListConstruct(%66, %66)
  %1301 : int[] = prim::ListConstruct(%66, %66)
  %1302 : int[] = prim::ListConstruct(%60, %60)
  %input0.57 : Tensor = aten::conv2d(%out.18, %weight.136, %bias.136, %1300, %1301, %1302, %59) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.135 : bool = prim::GetAttr[name="training"](%_1.54)
   = prim::If(%training.135) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.69 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.54)
      %1306 : Tensor = aten::add_(%num_batches_tracked.69, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.137 : bool = prim::GetAttr[name="training"](%_1.54)
  %running_mean.69 : Tensor = prim::GetAttr[name="running_mean"](%_1.54)
  %running_var.69 : Tensor = prim::GetAttr[name="running_var"](%_1.54)
  %weight.138 : Tensor = prim::GetAttr[name="weight"](%_1.54)
  %bias.138 : Tensor = prim::GetAttr[name="bias"](%_1.54)
   = prim::If(%training.137) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1312 : int[] = aten::size(%input0.57) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.69 : int = aten::__getitem__(%1312, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1314 : int = aten::len(%1312) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1315 : int = aten::sub(%1314, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.139 : int = prim::Loop(%1315, %67, %size_prods.69) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.69 : int, %size_prods0.141 : int):
          %1319 : int = aten::add(%i.69, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1320 : int = aten::__getitem__(%1312, %1319) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.69 : int = aten::mul(%size_prods0.141, %1320) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.69)
      %1322 : bool = aten::eq(%size_prods0.139, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1322) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1323 : str = aten::format(%65, %1312) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1323, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.41 : Tensor = aten::batch_norm(%input0.57, %weight.138, %bias.138, %running_mean.69, %running_var.69, %training.137, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out0.18 : Tensor = aten::gelu(%input1.41, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %srm.18 : __torch__.___torch_mangle_17.SRMLayer = prim::GetAttr[name="srm"](%_8)
  %1327 : int[] = aten::size(%out0.18) # /home/auto_update_valid_train.py:179:21
  %b.18 : int, %c.18 : int, %1330 : int, %1331 : int = prim::ListUnpack(%1327)
  %1332 : int[] = prim::ListConstruct(%b.18, %c.18, %70)
  %1333 : Tensor = aten::view(%out0.18, %1332) # /home/auto_update_valid_train.py:182:15
  %1334 : int[] = prim::ListConstruct(%70)
  %1335 : Tensor = aten::mean(%1333, %1334, %71, %72) # /home/auto_update_valid_train.py:182:15
  %mean.18 : Tensor = aten::unsqueeze(%1335, %70) # /home/auto_update_valid_train.py:182:15
  %1337 : int[] = prim::ListConstruct(%b.18, %c.18, %70)
  %1338 : Tensor = aten::view(%out0.18, %1337) # /home/auto_update_valid_train.py:183:14
  %1339 : int[] = prim::ListConstruct(%70)
  %1340 : Tensor = aten::std(%1338, %1339, %67, %71) # /home/auto_update_valid_train.py:183:14
  %std.18 : Tensor = aten::unsqueeze(%1340, %70) # /home/auto_update_valid_train.py:183:14
  %1342 : Tensor[] = prim::ListConstruct(%mean.18, %std.18)
  %u.18 : Tensor = aten::cat(%1342, %70) # /home/auto_update_valid_train.py:184:12
  %cfc.18 : __torch__.torch.nn.modules.conv.___torch_mangle_15.Conv1d = prim::GetAttr[name="cfc"](%srm.18)
  %weight.140 : Tensor = prim::GetAttr[name="weight"](%cfc.18)
  %bias.140 : Tensor? = prim::GetAttr[name="bias"](%cfc.18)
  %1347 : int[] = prim::ListConstruct(%60)
  %1348 : int[] = prim::ListConstruct(%68)
  %1349 : int[] = prim::ListConstruct(%60)
  %z.18 : Tensor = aten::conv1d(%u.18, %weight.140, %bias.140, %1347, %1348, %1349, %59) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:370:15
  %bn.18 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm1d = prim::GetAttr[name="bn"](%srm.18)
  %training.139 : bool = prim::GetAttr[name="training"](%bn.18)
   = prim::If(%training.139) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.71 : Tensor = prim::GetAttr[name="num_batches_tracked"](%bn.18)
      %1354 : Tensor = aten::add_(%num_batches_tracked.71, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.141 : bool = prim::GetAttr[name="training"](%bn.18)
  %running_mean.71 : Tensor = prim::GetAttr[name="running_mean"](%bn.18)
  %running_var.71 : Tensor = prim::GetAttr[name="running_var"](%bn.18)
  %weight.142 : Tensor = prim::GetAttr[name="weight"](%bn.18)
  %bias.142 : Tensor = prim::GetAttr[name="bias"](%bn.18)
   = prim::If(%training.141) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1360 : int[] = aten::size(%z.18) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.71 : int = aten::__getitem__(%1360, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1362 : int = aten::len(%1360) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1363 : int = aten::sub(%1362, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.143 : int = prim::Loop(%1363, %67, %size_prods.71) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.71 : int, %size_prods0.145 : int):
          %1367 : int = aten::add(%i.71, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1368 : int = aten::__getitem__(%1360, %1367) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.71 : int = aten::mul(%size_prods0.145, %1368) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.71)
      %1370 : bool = aten::eq(%size_prods0.143, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1370) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1371 : str = aten::format(%65, %1360) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1371, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %z0.18 : Tensor = aten::batch_norm(%z.18, %weight.142, %bias.142, %running_mean.71, %running_var.71, %training.141, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %g.18 : Tensor = aten::sigmoid(%z0.18) # /home/auto_update_valid_train.py:189:12
  %1374 : int[] = prim::ListConstruct(%b.18, %c.18, %60, %60)
  %g0.18 : Tensor = aten::view(%g.18, %1374) # /home/auto_update_valid_train.py:190:12
  %1376 : Tensor = aten::expand_as(%g0.18, %out0.18) # /home/auto_update_valid_train.py:192:19
  %out1.18 : Tensor = aten::mul(%out0.18, %1376) # /home/auto_update_valid_train.py:192:15
  %project_conv.18 : __torch__.torch.nn.modules.container.___torch_mangle_14.Sequential = prim::GetAttr[name="project_conv"](%_8)
  %_0.56 : __torch__.torch.nn.modules.conv.___torch_mangle_12.Conv2d = prim::GetAttr[name="0"](%project_conv.18)
  %_1.56 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%project_conv.18)
  %weight.144 : Tensor = prim::GetAttr[name="weight"](%_0.56)
  %bias.144 : Tensor? = prim::GetAttr[name="bias"](%_0.56)
  %1383 : int[] = prim::ListConstruct(%60, %60)
  %1384 : int[] = prim::ListConstruct(%68, %68)
  %1385 : int[] = prim::ListConstruct(%60, %60)
  %input0.59 : Tensor = aten::conv2d(%out1.18, %weight.144, %bias.144, %1383, %1384, %1385, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.143 : bool = prim::GetAttr[name="training"](%_1.56)
   = prim::If(%training.143) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.73 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.56)
      %1389 : Tensor = aten::add_(%num_batches_tracked.73, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.145 : bool = prim::GetAttr[name="training"](%_1.56)
  %running_mean.73 : Tensor = prim::GetAttr[name="running_mean"](%_1.56)
  %running_var.73 : Tensor = prim::GetAttr[name="running_var"](%_1.56)
  %weight.146 : Tensor = prim::GetAttr[name="weight"](%_1.56)
  %bias.146 : Tensor = prim::GetAttr[name="bias"](%_1.56)
   = prim::If(%training.145) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1395 : int[] = aten::size(%input0.59) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.73 : int = aten::__getitem__(%1395, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1397 : int = aten::len(%1395) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1398 : int = aten::sub(%1397, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.147 : int = prim::Loop(%1398, %67, %size_prods.73) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.73 : int, %size_prods0.149 : int):
          %1402 : int = aten::add(%i.73, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1403 : int = aten::__getitem__(%1395, %1402) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.73 : int = aten::mul(%size_prods0.149, %1403) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.73)
      %1405 : bool = aten::eq(%size_prods0.147, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1405) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1406 : str = aten::format(%65, %1395) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1406, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out2.18 : Tensor = aten::batch_norm(%input0.59, %weight.146, %bias.146, %running_mean.73, %running_var.73, %training.145, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %use_residual.18 : bool = prim::GetAttr[name="use_residual"](%_8)
  %input8.1 : Tensor = prim::If(%use_residual.18) # /home/auto_update_valid_train.py:261:8
    block0():
      %out3.18 : Tensor = aten::add(%out2.18, %input7.1, %60) # /home/auto_update_valid_train.py:263:18
      -> (%out3.18)
    block1():
      -> (%out2.18)
  %expand_conv.20 : __torch__.torch.nn.modules.container.___torch_mangle_21.Sequential = prim::GetAttr[name="expand_conv"](%_9)
  %_0.58 : __torch__.torch.nn.modules.conv.___torch_mangle_19.Conv2d = prim::GetAttr[name="0"](%expand_conv.20)
  %_1.58 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_20.BatchNorm2d = prim::GetAttr[name="1"](%expand_conv.20)
  %weight.148 : Tensor = prim::GetAttr[name="weight"](%_0.58)
  %bias.148 : Tensor? = prim::GetAttr[name="bias"](%_0.58)
  %1416 : int[] = prim::ListConstruct(%60, %60)
  %1417 : int[] = prim::ListConstruct(%68, %68)
  %1418 : int[] = prim::ListConstruct(%60, %60)
  %input0.61 : Tensor = aten::conv2d(%input8.1, %weight.148, %bias.148, %1416, %1417, %1418, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.147 : bool = prim::GetAttr[name="training"](%_1.58)
   = prim::If(%training.147) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.75 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.58)
      %1422 : Tensor = aten::add_(%num_batches_tracked.75, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.149 : bool = prim::GetAttr[name="training"](%_1.58)
  %running_mean.75 : Tensor = prim::GetAttr[name="running_mean"](%_1.58)
  %running_var.75 : Tensor = prim::GetAttr[name="running_var"](%_1.58)
  %weight.150 : Tensor = prim::GetAttr[name="weight"](%_1.58)
  %bias.150 : Tensor = prim::GetAttr[name="bias"](%_1.58)
   = prim::If(%training.149) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1428 : int[] = aten::size(%input0.61) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.75 : int = aten::__getitem__(%1428, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1430 : int = aten::len(%1428) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1431 : int = aten::sub(%1430, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.151 : int = prim::Loop(%1431, %67, %size_prods.75) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.75 : int, %size_prods0.153 : int):
          %1435 : int = aten::add(%i.75, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1436 : int = aten::__getitem__(%1428, %1435) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.75 : int = aten::mul(%size_prods0.153, %1436) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.75)
      %1438 : bool = aten::eq(%size_prods0.151, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1438) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1439 : str = aten::format(%65, %1428) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1439, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.43 : Tensor = aten::batch_norm(%input0.61, %weight.150, %bias.150, %running_mean.75, %running_var.75, %training.149, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out.20 : Tensor = aten::gelu(%input1.43, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %depthwise_conv.20 : __torch__.torch.nn.modules.container.___torch_mangle_23.Sequential = prim::GetAttr[name="depthwise_conv"](%_9)
  %_0.60 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="0"](%depthwise_conv.20)
  %_1.60 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_20.BatchNorm2d = prim::GetAttr[name="1"](%depthwise_conv.20)
  %weight.152 : Tensor = prim::GetAttr[name="weight"](%_0.60)
  %bias.152 : Tensor? = prim::GetAttr[name="bias"](%_0.60)
  %1447 : int[] = prim::ListConstruct(%60, %60)
  %1448 : int[] = prim::ListConstruct(%66, %66)
  %1449 : int[] = prim::ListConstruct(%60, %60)
  %input0.63 : Tensor = aten::conv2d(%out.20, %weight.152, %bias.152, %1447, %1448, %1449, %58) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.151 : bool = prim::GetAttr[name="training"](%_1.60)
   = prim::If(%training.151) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.77 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.60)
      %1453 : Tensor = aten::add_(%num_batches_tracked.77, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.153 : bool = prim::GetAttr[name="training"](%_1.60)
  %running_mean.77 : Tensor = prim::GetAttr[name="running_mean"](%_1.60)
  %running_var.77 : Tensor = prim::GetAttr[name="running_var"](%_1.60)
  %weight.154 : Tensor = prim::GetAttr[name="weight"](%_1.60)
  %bias.154 : Tensor = prim::GetAttr[name="bias"](%_1.60)
   = prim::If(%training.153) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1459 : int[] = aten::size(%input0.63) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.77 : int = aten::__getitem__(%1459, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1461 : int = aten::len(%1459) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1462 : int = aten::sub(%1461, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.155 : int = prim::Loop(%1462, %67, %size_prods.77) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.77 : int, %size_prods0.157 : int):
          %1466 : int = aten::add(%i.77, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1467 : int = aten::__getitem__(%1459, %1466) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.77 : int = aten::mul(%size_prods0.157, %1467) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.77)
      %1469 : bool = aten::eq(%size_prods0.155, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1469) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1470 : str = aten::format(%65, %1459) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1470, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.45 : Tensor = aten::batch_norm(%input0.63, %weight.154, %bias.154, %running_mean.77, %running_var.77, %training.153, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out0.20 : Tensor = aten::gelu(%input1.45, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %srm.20 : __torch__.___torch_mangle_28.SRMLayer = prim::GetAttr[name="srm"](%_9)
  %1474 : int[] = aten::size(%out0.20) # /home/auto_update_valid_train.py:179:21
  %b.20 : int, %c.20 : int, %1477 : int, %1478 : int = prim::ListUnpack(%1474)
  %1479 : int[] = prim::ListConstruct(%b.20, %c.20, %70)
  %1480 : Tensor = aten::view(%out0.20, %1479) # /home/auto_update_valid_train.py:182:15
  %1481 : int[] = prim::ListConstruct(%70)
  %1482 : Tensor = aten::mean(%1480, %1481, %71, %72) # /home/auto_update_valid_train.py:182:15
  %mean.20 : Tensor = aten::unsqueeze(%1482, %70) # /home/auto_update_valid_train.py:182:15
  %1484 : int[] = prim::ListConstruct(%b.20, %c.20, %70)
  %1485 : Tensor = aten::view(%out0.20, %1484) # /home/auto_update_valid_train.py:183:14
  %1486 : int[] = prim::ListConstruct(%70)
  %1487 : Tensor = aten::std(%1485, %1486, %67, %71) # /home/auto_update_valid_train.py:183:14
  %std.20 : Tensor = aten::unsqueeze(%1487, %70) # /home/auto_update_valid_train.py:183:14
  %1489 : Tensor[] = prim::ListConstruct(%mean.20, %std.20)
  %u.20 : Tensor = aten::cat(%1489, %70) # /home/auto_update_valid_train.py:184:12
  %cfc.20 : __torch__.torch.nn.modules.conv.___torch_mangle_26.Conv1d = prim::GetAttr[name="cfc"](%srm.20)
  %weight.156 : Tensor = prim::GetAttr[name="weight"](%cfc.20)
  %bias.156 : Tensor? = prim::GetAttr[name="bias"](%cfc.20)
  %1494 : int[] = prim::ListConstruct(%60)
  %1495 : int[] = prim::ListConstruct(%68)
  %1496 : int[] = prim::ListConstruct(%60)
  %z.20 : Tensor = aten::conv1d(%u.20, %weight.156, %bias.156, %1494, %1495, %1496, %58) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:370:15
  %bn.20 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_27.BatchNorm1d = prim::GetAttr[name="bn"](%srm.20)
  %training.155 : bool = prim::GetAttr[name="training"](%bn.20)
   = prim::If(%training.155) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.79 : Tensor = prim::GetAttr[name="num_batches_tracked"](%bn.20)
      %1501 : Tensor = aten::add_(%num_batches_tracked.79, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.157 : bool = prim::GetAttr[name="training"](%bn.20)
  %running_mean.79 : Tensor = prim::GetAttr[name="running_mean"](%bn.20)
  %running_var.79 : Tensor = prim::GetAttr[name="running_var"](%bn.20)
  %weight.158 : Tensor = prim::GetAttr[name="weight"](%bn.20)
  %bias.158 : Tensor = prim::GetAttr[name="bias"](%bn.20)
   = prim::If(%training.157) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1507 : int[] = aten::size(%z.20) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.79 : int = aten::__getitem__(%1507, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1509 : int = aten::len(%1507) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1510 : int = aten::sub(%1509, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.159 : int = prim::Loop(%1510, %67, %size_prods.79) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.79 : int, %size_prods0.161 : int):
          %1514 : int = aten::add(%i.79, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1515 : int = aten::__getitem__(%1507, %1514) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.79 : int = aten::mul(%size_prods0.161, %1515) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.79)
      %1517 : bool = aten::eq(%size_prods0.159, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1517) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1518 : str = aten::format(%65, %1507) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1518, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %z0.20 : Tensor = aten::batch_norm(%z.20, %weight.158, %bias.158, %running_mean.79, %running_var.79, %training.157, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %g.20 : Tensor = aten::sigmoid(%z0.20) # /home/auto_update_valid_train.py:189:12
  %1521 : int[] = prim::ListConstruct(%b.20, %c.20, %60, %60)
  %g0.20 : Tensor = aten::view(%g.20, %1521) # /home/auto_update_valid_train.py:190:12
  %1523 : Tensor = aten::expand_as(%g0.20, %out0.20) # /home/auto_update_valid_train.py:192:19
  %out1.20 : Tensor = aten::mul(%out0.20, %1523) # /home/auto_update_valid_train.py:192:15
  %project_conv.20 : __torch__.torch.nn.modules.container.___torch_mangle_25.Sequential = prim::GetAttr[name="project_conv"](%_9)
  %_0.62 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="0"](%project_conv.20)
  %_1.62 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%project_conv.20)
  %weight.160 : Tensor = prim::GetAttr[name="weight"](%_0.62)
  %bias.160 : Tensor? = prim::GetAttr[name="bias"](%_0.62)
  %1530 : int[] = prim::ListConstruct(%60, %60)
  %1531 : int[] = prim::ListConstruct(%68, %68)
  %1532 : int[] = prim::ListConstruct(%60, %60)
  %input0.65 : Tensor = aten::conv2d(%out1.20, %weight.160, %bias.160, %1530, %1531, %1532, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.159 : bool = prim::GetAttr[name="training"](%_1.62)
   = prim::If(%training.159) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.81 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.62)
      %1536 : Tensor = aten::add_(%num_batches_tracked.81, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.161 : bool = prim::GetAttr[name="training"](%_1.62)
  %running_mean.81 : Tensor = prim::GetAttr[name="running_mean"](%_1.62)
  %running_var.81 : Tensor = prim::GetAttr[name="running_var"](%_1.62)
  %weight.162 : Tensor = prim::GetAttr[name="weight"](%_1.62)
  %bias.162 : Tensor = prim::GetAttr[name="bias"](%_1.62)
   = prim::If(%training.161) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1542 : int[] = aten::size(%input0.65) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.81 : int = aten::__getitem__(%1542, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1544 : int = aten::len(%1542) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1545 : int = aten::sub(%1544, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.163 : int = prim::Loop(%1545, %67, %size_prods.81) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.81 : int, %size_prods0.165 : int):
          %1549 : int = aten::add(%i.81, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1550 : int = aten::__getitem__(%1542, %1549) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.81 : int = aten::mul(%size_prods0.165, %1550) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.81)
      %1552 : bool = aten::eq(%size_prods0.163, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1552) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1553 : str = aten::format(%65, %1542) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1553, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out2.20 : Tensor = aten::batch_norm(%input0.65, %weight.162, %bias.162, %running_mean.81, %running_var.81, %training.161, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %use_residual.20 : bool = prim::GetAttr[name="use_residual"](%_9)
  %input9.1 : Tensor = prim::If(%use_residual.20) # /home/auto_update_valid_train.py:261:8
    block0():
      %out3.20 : Tensor = aten::add(%out2.20, %input8.1, %60) # /home/auto_update_valid_train.py:263:18
      -> (%out3.20)
    block1():
      -> (%out2.20)
  %expand_conv.22 : __torch__.torch.nn.modules.container.___torch_mangle_21.Sequential = prim::GetAttr[name="expand_conv"](%_10)
  %_0.64 : __torch__.torch.nn.modules.conv.___torch_mangle_19.Conv2d = prim::GetAttr[name="0"](%expand_conv.22)
  %_1.64 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_20.BatchNorm2d = prim::GetAttr[name="1"](%expand_conv.22)
  %weight.164 : Tensor = prim::GetAttr[name="weight"](%_0.64)
  %bias.164 : Tensor? = prim::GetAttr[name="bias"](%_0.64)
  %1563 : int[] = prim::ListConstruct(%60, %60)
  %1564 : int[] = prim::ListConstruct(%68, %68)
  %1565 : int[] = prim::ListConstruct(%60, %60)
  %input0.67 : Tensor = aten::conv2d(%input9.1, %weight.164, %bias.164, %1563, %1564, %1565, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.163 : bool = prim::GetAttr[name="training"](%_1.64)
   = prim::If(%training.163) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.83 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.64)
      %1569 : Tensor = aten::add_(%num_batches_tracked.83, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.165 : bool = prim::GetAttr[name="training"](%_1.64)
  %running_mean.83 : Tensor = prim::GetAttr[name="running_mean"](%_1.64)
  %running_var.83 : Tensor = prim::GetAttr[name="running_var"](%_1.64)
  %weight.166 : Tensor = prim::GetAttr[name="weight"](%_1.64)
  %bias.166 : Tensor = prim::GetAttr[name="bias"](%_1.64)
   = prim::If(%training.165) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1575 : int[] = aten::size(%input0.67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.83 : int = aten::__getitem__(%1575, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1577 : int = aten::len(%1575) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1578 : int = aten::sub(%1577, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.167 : int = prim::Loop(%1578, %67, %size_prods.83) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.83 : int, %size_prods0.169 : int):
          %1582 : int = aten::add(%i.83, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1583 : int = aten::__getitem__(%1575, %1582) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.83 : int = aten::mul(%size_prods0.169, %1583) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.83)
      %1585 : bool = aten::eq(%size_prods0.167, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1585) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1586 : str = aten::format(%65, %1575) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1586, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.47 : Tensor = aten::batch_norm(%input0.67, %weight.166, %bias.166, %running_mean.83, %running_var.83, %training.165, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out.22 : Tensor = aten::gelu(%input1.47, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %depthwise_conv.22 : __torch__.torch.nn.modules.container.___torch_mangle_23.Sequential = prim::GetAttr[name="depthwise_conv"](%_10)
  %_0.66 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="0"](%depthwise_conv.22)
  %_1.66 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_20.BatchNorm2d = prim::GetAttr[name="1"](%depthwise_conv.22)
  %weight.168 : Tensor = prim::GetAttr[name="weight"](%_0.66)
  %bias.168 : Tensor? = prim::GetAttr[name="bias"](%_0.66)
  %1594 : int[] = prim::ListConstruct(%60, %60)
  %1595 : int[] = prim::ListConstruct(%66, %66)
  %1596 : int[] = prim::ListConstruct(%60, %60)
  %input0.69 : Tensor = aten::conv2d(%out.22, %weight.168, %bias.168, %1594, %1595, %1596, %58) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.167 : bool = prim::GetAttr[name="training"](%_1.66)
   = prim::If(%training.167) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.85 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.66)
      %1600 : Tensor = aten::add_(%num_batches_tracked.85, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.169 : bool = prim::GetAttr[name="training"](%_1.66)
  %running_mean.85 : Tensor = prim::GetAttr[name="running_mean"](%_1.66)
  %running_var.85 : Tensor = prim::GetAttr[name="running_var"](%_1.66)
  %weight.170 : Tensor = prim::GetAttr[name="weight"](%_1.66)
  %bias.170 : Tensor = prim::GetAttr[name="bias"](%_1.66)
   = prim::If(%training.169) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1606 : int[] = aten::size(%input0.69) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.85 : int = aten::__getitem__(%1606, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1608 : int = aten::len(%1606) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1609 : int = aten::sub(%1608, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.171 : int = prim::Loop(%1609, %67, %size_prods.85) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.85 : int, %size_prods0.173 : int):
          %1613 : int = aten::add(%i.85, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1614 : int = aten::__getitem__(%1606, %1613) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.85 : int = aten::mul(%size_prods0.173, %1614) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.85)
      %1616 : bool = aten::eq(%size_prods0.171, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1616) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1617 : str = aten::format(%65, %1606) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1617, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.49 : Tensor = aten::batch_norm(%input0.69, %weight.170, %bias.170, %running_mean.85, %running_var.85, %training.169, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out0.22 : Tensor = aten::gelu(%input1.49, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %srm.22 : __torch__.___torch_mangle_28.SRMLayer = prim::GetAttr[name="srm"](%_10)
  %1621 : int[] = aten::size(%out0.22) # /home/auto_update_valid_train.py:179:21
  %b.22 : int, %c.22 : int, %1624 : int, %1625 : int = prim::ListUnpack(%1621)
  %1626 : int[] = prim::ListConstruct(%b.22, %c.22, %70)
  %1627 : Tensor = aten::view(%out0.22, %1626) # /home/auto_update_valid_train.py:182:15
  %1628 : int[] = prim::ListConstruct(%70)
  %1629 : Tensor = aten::mean(%1627, %1628, %71, %72) # /home/auto_update_valid_train.py:182:15
  %mean.22 : Tensor = aten::unsqueeze(%1629, %70) # /home/auto_update_valid_train.py:182:15
  %1631 : int[] = prim::ListConstruct(%b.22, %c.22, %70)
  %1632 : Tensor = aten::view(%out0.22, %1631) # /home/auto_update_valid_train.py:183:14
  %1633 : int[] = prim::ListConstruct(%70)
  %1634 : Tensor = aten::std(%1632, %1633, %67, %71) # /home/auto_update_valid_train.py:183:14
  %std.22 : Tensor = aten::unsqueeze(%1634, %70) # /home/auto_update_valid_train.py:183:14
  %1636 : Tensor[] = prim::ListConstruct(%mean.22, %std.22)
  %u.22 : Tensor = aten::cat(%1636, %70) # /home/auto_update_valid_train.py:184:12
  %cfc.22 : __torch__.torch.nn.modules.conv.___torch_mangle_26.Conv1d = prim::GetAttr[name="cfc"](%srm.22)
  %weight.172 : Tensor = prim::GetAttr[name="weight"](%cfc.22)
  %bias.172 : Tensor? = prim::GetAttr[name="bias"](%cfc.22)
  %1641 : int[] = prim::ListConstruct(%60)
  %1642 : int[] = prim::ListConstruct(%68)
  %1643 : int[] = prim::ListConstruct(%60)
  %z.22 : Tensor = aten::conv1d(%u.22, %weight.172, %bias.172, %1641, %1642, %1643, %58) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:370:15
  %bn.22 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_27.BatchNorm1d = prim::GetAttr[name="bn"](%srm.22)
  %training.171 : bool = prim::GetAttr[name="training"](%bn.22)
   = prim::If(%training.171) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.87 : Tensor = prim::GetAttr[name="num_batches_tracked"](%bn.22)
      %1648 : Tensor = aten::add_(%num_batches_tracked.87, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.173 : bool = prim::GetAttr[name="training"](%bn.22)
  %running_mean.87 : Tensor = prim::GetAttr[name="running_mean"](%bn.22)
  %running_var.87 : Tensor = prim::GetAttr[name="running_var"](%bn.22)
  %weight.174 : Tensor = prim::GetAttr[name="weight"](%bn.22)
  %bias.174 : Tensor = prim::GetAttr[name="bias"](%bn.22)
   = prim::If(%training.173) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1654 : int[] = aten::size(%z.22) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.87 : int = aten::__getitem__(%1654, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1656 : int = aten::len(%1654) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1657 : int = aten::sub(%1656, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.175 : int = prim::Loop(%1657, %67, %size_prods.87) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.87 : int, %size_prods0.177 : int):
          %1661 : int = aten::add(%i.87, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1662 : int = aten::__getitem__(%1654, %1661) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.87 : int = aten::mul(%size_prods0.177, %1662) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.87)
      %1664 : bool = aten::eq(%size_prods0.175, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1664) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1665 : str = aten::format(%65, %1654) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1665, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %z0.22 : Tensor = aten::batch_norm(%z.22, %weight.174, %bias.174, %running_mean.87, %running_var.87, %training.173, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %g.22 : Tensor = aten::sigmoid(%z0.22) # /home/auto_update_valid_train.py:189:12
  %1668 : int[] = prim::ListConstruct(%b.22, %c.22, %60, %60)
  %g0.22 : Tensor = aten::view(%g.22, %1668) # /home/auto_update_valid_train.py:190:12
  %1670 : Tensor = aten::expand_as(%g0.22, %out0.22) # /home/auto_update_valid_train.py:192:19
  %out1.22 : Tensor = aten::mul(%out0.22, %1670) # /home/auto_update_valid_train.py:192:15
  %project_conv.22 : __torch__.torch.nn.modules.container.___torch_mangle_25.Sequential = prim::GetAttr[name="project_conv"](%_10)
  %_0.68 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="0"](%project_conv.22)
  %_1.68 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%project_conv.22)
  %weight.176 : Tensor = prim::GetAttr[name="weight"](%_0.68)
  %bias.176 : Tensor? = prim::GetAttr[name="bias"](%_0.68)
  %1677 : int[] = prim::ListConstruct(%60, %60)
  %1678 : int[] = prim::ListConstruct(%68, %68)
  %1679 : int[] = prim::ListConstruct(%60, %60)
  %input0.71 : Tensor = aten::conv2d(%out1.22, %weight.176, %bias.176, %1677, %1678, %1679, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.175 : bool = prim::GetAttr[name="training"](%_1.68)
   = prim::If(%training.175) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.89 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.68)
      %1683 : Tensor = aten::add_(%num_batches_tracked.89, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.177 : bool = prim::GetAttr[name="training"](%_1.68)
  %running_mean.89 : Tensor = prim::GetAttr[name="running_mean"](%_1.68)
  %running_var.89 : Tensor = prim::GetAttr[name="running_var"](%_1.68)
  %weight.178 : Tensor = prim::GetAttr[name="weight"](%_1.68)
  %bias.178 : Tensor = prim::GetAttr[name="bias"](%_1.68)
   = prim::If(%training.177) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1689 : int[] = aten::size(%input0.71) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.89 : int = aten::__getitem__(%1689, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1691 : int = aten::len(%1689) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1692 : int = aten::sub(%1691, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.179 : int = prim::Loop(%1692, %67, %size_prods.89) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.89 : int, %size_prods0.181 : int):
          %1696 : int = aten::add(%i.89, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1697 : int = aten::__getitem__(%1689, %1696) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.89 : int = aten::mul(%size_prods0.181, %1697) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.89)
      %1699 : bool = aten::eq(%size_prods0.179, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1699) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1700 : str = aten::format(%65, %1689) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1700, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out2.22 : Tensor = aten::batch_norm(%input0.71, %weight.178, %bias.178, %running_mean.89, %running_var.89, %training.177, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %use_residual.22 : bool = prim::GetAttr[name="use_residual"](%_10)
  %input10.1 : Tensor = prim::If(%use_residual.22) # /home/auto_update_valid_train.py:261:8
    block0():
      %out3.22 : Tensor = aten::add(%out2.22, %input9.1, %60) # /home/auto_update_valid_train.py:263:18
      -> (%out3.22)
    block1():
      -> (%out2.22)
  %expand_conv.24 : __torch__.torch.nn.modules.container.___torch_mangle_21.Sequential = prim::GetAttr[name="expand_conv"](%_11)
  %_0.70 : __torch__.torch.nn.modules.conv.___torch_mangle_19.Conv2d = prim::GetAttr[name="0"](%expand_conv.24)
  %_1.70 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_20.BatchNorm2d = prim::GetAttr[name="1"](%expand_conv.24)
  %weight.180 : Tensor = prim::GetAttr[name="weight"](%_0.70)
  %bias.180 : Tensor? = prim::GetAttr[name="bias"](%_0.70)
  %1710 : int[] = prim::ListConstruct(%60, %60)
  %1711 : int[] = prim::ListConstruct(%68, %68)
  %1712 : int[] = prim::ListConstruct(%60, %60)
  %input0.73 : Tensor = aten::conv2d(%input10.1, %weight.180, %bias.180, %1710, %1711, %1712, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.179 : bool = prim::GetAttr[name="training"](%_1.70)
   = prim::If(%training.179) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.91 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.70)
      %1716 : Tensor = aten::add_(%num_batches_tracked.91, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.181 : bool = prim::GetAttr[name="training"](%_1.70)
  %running_mean.91 : Tensor = prim::GetAttr[name="running_mean"](%_1.70)
  %running_var.91 : Tensor = prim::GetAttr[name="running_var"](%_1.70)
  %weight.182 : Tensor = prim::GetAttr[name="weight"](%_1.70)
  %bias.182 : Tensor = prim::GetAttr[name="bias"](%_1.70)
   = prim::If(%training.181) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1722 : int[] = aten::size(%input0.73) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.91 : int = aten::__getitem__(%1722, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1724 : int = aten::len(%1722) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1725 : int = aten::sub(%1724, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.183 : int = prim::Loop(%1725, %67, %size_prods.91) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.91 : int, %size_prods0.185 : int):
          %1729 : int = aten::add(%i.91, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1730 : int = aten::__getitem__(%1722, %1729) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.91 : int = aten::mul(%size_prods0.185, %1730) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.91)
      %1732 : bool = aten::eq(%size_prods0.183, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1732) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1733 : str = aten::format(%65, %1722) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1733, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.51 : Tensor = aten::batch_norm(%input0.73, %weight.182, %bias.182, %running_mean.91, %running_var.91, %training.181, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out.24 : Tensor = aten::gelu(%input1.51, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %depthwise_conv.24 : __torch__.torch.nn.modules.container.___torch_mangle_23.Sequential = prim::GetAttr[name="depthwise_conv"](%_11)
  %_0.72 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="0"](%depthwise_conv.24)
  %_1.72 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_20.BatchNorm2d = prim::GetAttr[name="1"](%depthwise_conv.24)
  %weight.184 : Tensor = prim::GetAttr[name="weight"](%_0.72)
  %bias.184 : Tensor? = prim::GetAttr[name="bias"](%_0.72)
  %1741 : int[] = prim::ListConstruct(%60, %60)
  %1742 : int[] = prim::ListConstruct(%66, %66)
  %1743 : int[] = prim::ListConstruct(%60, %60)
  %input0.75 : Tensor = aten::conv2d(%out.24, %weight.184, %bias.184, %1741, %1742, %1743, %58) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.183 : bool = prim::GetAttr[name="training"](%_1.72)
   = prim::If(%training.183) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.93 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.72)
      %1747 : Tensor = aten::add_(%num_batches_tracked.93, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.185 : bool = prim::GetAttr[name="training"](%_1.72)
  %running_mean.93 : Tensor = prim::GetAttr[name="running_mean"](%_1.72)
  %running_var.93 : Tensor = prim::GetAttr[name="running_var"](%_1.72)
  %weight.186 : Tensor = prim::GetAttr[name="weight"](%_1.72)
  %bias.186 : Tensor = prim::GetAttr[name="bias"](%_1.72)
   = prim::If(%training.185) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1753 : int[] = aten::size(%input0.75) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.93 : int = aten::__getitem__(%1753, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1755 : int = aten::len(%1753) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1756 : int = aten::sub(%1755, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.187 : int = prim::Loop(%1756, %67, %size_prods.93) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.93 : int, %size_prods0.189 : int):
          %1760 : int = aten::add(%i.93, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1761 : int = aten::__getitem__(%1753, %1760) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.93 : int = aten::mul(%size_prods0.189, %1761) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.93)
      %1763 : bool = aten::eq(%size_prods0.187, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1763) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1764 : str = aten::format(%65, %1753) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1764, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.53 : Tensor = aten::batch_norm(%input0.75, %weight.186, %bias.186, %running_mean.93, %running_var.93, %training.185, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out0.24 : Tensor = aten::gelu(%input1.53, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %srm.24 : __torch__.___torch_mangle_28.SRMLayer = prim::GetAttr[name="srm"](%_11)
  %1768 : int[] = aten::size(%out0.24) # /home/auto_update_valid_train.py:179:21
  %b.24 : int, %c.24 : int, %1771 : int, %1772 : int = prim::ListUnpack(%1768)
  %1773 : int[] = prim::ListConstruct(%b.24, %c.24, %70)
  %1774 : Tensor = aten::view(%out0.24, %1773) # /home/auto_update_valid_train.py:182:15
  %1775 : int[] = prim::ListConstruct(%70)
  %1776 : Tensor = aten::mean(%1774, %1775, %71, %72) # /home/auto_update_valid_train.py:182:15
  %mean.24 : Tensor = aten::unsqueeze(%1776, %70) # /home/auto_update_valid_train.py:182:15
  %1778 : int[] = prim::ListConstruct(%b.24, %c.24, %70)
  %1779 : Tensor = aten::view(%out0.24, %1778) # /home/auto_update_valid_train.py:183:14
  %1780 : int[] = prim::ListConstruct(%70)
  %1781 : Tensor = aten::std(%1779, %1780, %67, %71) # /home/auto_update_valid_train.py:183:14
  %std.24 : Tensor = aten::unsqueeze(%1781, %70) # /home/auto_update_valid_train.py:183:14
  %1783 : Tensor[] = prim::ListConstruct(%mean.24, %std.24)
  %u.24 : Tensor = aten::cat(%1783, %70) # /home/auto_update_valid_train.py:184:12
  %cfc.24 : __torch__.torch.nn.modules.conv.___torch_mangle_26.Conv1d = prim::GetAttr[name="cfc"](%srm.24)
  %weight.188 : Tensor = prim::GetAttr[name="weight"](%cfc.24)
  %bias.188 : Tensor? = prim::GetAttr[name="bias"](%cfc.24)
  %1788 : int[] = prim::ListConstruct(%60)
  %1789 : int[] = prim::ListConstruct(%68)
  %1790 : int[] = prim::ListConstruct(%60)
  %z.24 : Tensor = aten::conv1d(%u.24, %weight.188, %bias.188, %1788, %1789, %1790, %58) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:370:15
  %bn.24 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_27.BatchNorm1d = prim::GetAttr[name="bn"](%srm.24)
  %training.187 : bool = prim::GetAttr[name="training"](%bn.24)
   = prim::If(%training.187) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.95 : Tensor = prim::GetAttr[name="num_batches_tracked"](%bn.24)
      %1795 : Tensor = aten::add_(%num_batches_tracked.95, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.189 : bool = prim::GetAttr[name="training"](%bn.24)
  %running_mean.95 : Tensor = prim::GetAttr[name="running_mean"](%bn.24)
  %running_var.95 : Tensor = prim::GetAttr[name="running_var"](%bn.24)
  %weight.190 : Tensor = prim::GetAttr[name="weight"](%bn.24)
  %bias.190 : Tensor = prim::GetAttr[name="bias"](%bn.24)
   = prim::If(%training.189) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1801 : int[] = aten::size(%z.24) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.95 : int = aten::__getitem__(%1801, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1803 : int = aten::len(%1801) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1804 : int = aten::sub(%1803, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.191 : int = prim::Loop(%1804, %67, %size_prods.95) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.95 : int, %size_prods0.193 : int):
          %1808 : int = aten::add(%i.95, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1809 : int = aten::__getitem__(%1801, %1808) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.95 : int = aten::mul(%size_prods0.193, %1809) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.95)
      %1811 : bool = aten::eq(%size_prods0.191, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1811) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1812 : str = aten::format(%65, %1801) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1812, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %z0.24 : Tensor = aten::batch_norm(%z.24, %weight.190, %bias.190, %running_mean.95, %running_var.95, %training.189, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %g.24 : Tensor = aten::sigmoid(%z0.24) # /home/auto_update_valid_train.py:189:12
  %1815 : int[] = prim::ListConstruct(%b.24, %c.24, %60, %60)
  %g0.24 : Tensor = aten::view(%g.24, %1815) # /home/auto_update_valid_train.py:190:12
  %1817 : Tensor = aten::expand_as(%g0.24, %out0.24) # /home/auto_update_valid_train.py:192:19
  %out1.24 : Tensor = aten::mul(%out0.24, %1817) # /home/auto_update_valid_train.py:192:15
  %project_conv.24 : __torch__.torch.nn.modules.container.___torch_mangle_25.Sequential = prim::GetAttr[name="project_conv"](%_11)
  %_0.74 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="0"](%project_conv.24)
  %_1.74 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%project_conv.24)
  %weight.192 : Tensor = prim::GetAttr[name="weight"](%_0.74)
  %bias.192 : Tensor? = prim::GetAttr[name="bias"](%_0.74)
  %1824 : int[] = prim::ListConstruct(%60, %60)
  %1825 : int[] = prim::ListConstruct(%68, %68)
  %1826 : int[] = prim::ListConstruct(%60, %60)
  %input0.77 : Tensor = aten::conv2d(%out1.24, %weight.192, %bias.192, %1824, %1825, %1826, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.191 : bool = prim::GetAttr[name="training"](%_1.74)
   = prim::If(%training.191) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.97 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.74)
      %1830 : Tensor = aten::add_(%num_batches_tracked.97, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.193 : bool = prim::GetAttr[name="training"](%_1.74)
  %running_mean.97 : Tensor = prim::GetAttr[name="running_mean"](%_1.74)
  %running_var.97 : Tensor = prim::GetAttr[name="running_var"](%_1.74)
  %weight.194 : Tensor = prim::GetAttr[name="weight"](%_1.74)
  %bias.194 : Tensor = prim::GetAttr[name="bias"](%_1.74)
   = prim::If(%training.193) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1836 : int[] = aten::size(%input0.77) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.97 : int = aten::__getitem__(%1836, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1838 : int = aten::len(%1836) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1839 : int = aten::sub(%1838, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.195 : int = prim::Loop(%1839, %67, %size_prods.97) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.97 : int, %size_prods0.197 : int):
          %1843 : int = aten::add(%i.97, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1844 : int = aten::__getitem__(%1836, %1843) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.97 : int = aten::mul(%size_prods0.197, %1844) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.97)
      %1846 : bool = aten::eq(%size_prods0.195, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1846) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1847 : str = aten::format(%65, %1836) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1847, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out2.24 : Tensor = aten::batch_norm(%input0.77, %weight.194, %bias.194, %running_mean.97, %running_var.97, %training.193, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %use_residual.24 : bool = prim::GetAttr[name="use_residual"](%_11)
  %input11.1 : Tensor = prim::If(%use_residual.24) # /home/auto_update_valid_train.py:261:8
    block0():
      %out3.24 : Tensor = aten::add(%out2.24, %input10.1, %60) # /home/auto_update_valid_train.py:263:18
      -> (%out3.24)
    block1():
      -> (%out2.24)
  %expand_conv.26 : __torch__.torch.nn.modules.container.___torch_mangle_299.Sequential = prim::GetAttr[name="expand_conv"](%_12)
  %_0.76 : __torch__.torch.nn.modules.conv.___torch_mangle_297.Conv2d = prim::GetAttr[name="0"](%expand_conv.26)
  %_1.76 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_298.BatchNorm2d = prim::GetAttr[name="1"](%expand_conv.26)
  %weight.196 : Tensor = prim::GetAttr[name="weight"](%_0.76)
  %bias.196 : Tensor? = prim::GetAttr[name="bias"](%_0.76)
  %1857 : int[] = prim::ListConstruct(%60, %60)
  %1858 : int[] = prim::ListConstruct(%68, %68)
  %1859 : int[] = prim::ListConstruct(%60, %60)
  %input0.79 : Tensor = aten::conv2d(%input11.1, %weight.196, %bias.196, %1857, %1858, %1859, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.195 : bool = prim::GetAttr[name="training"](%_1.76)
   = prim::If(%training.195) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.99 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.76)
      %1863 : Tensor = aten::add_(%num_batches_tracked.99, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.197 : bool = prim::GetAttr[name="training"](%_1.76)
  %running_mean.99 : Tensor = prim::GetAttr[name="running_mean"](%_1.76)
  %running_var.99 : Tensor = prim::GetAttr[name="running_var"](%_1.76)
  %weight.198 : Tensor = prim::GetAttr[name="weight"](%_1.76)
  %bias.198 : Tensor = prim::GetAttr[name="bias"](%_1.76)
   = prim::If(%training.197) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1869 : int[] = aten::size(%input0.79) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.99 : int = aten::__getitem__(%1869, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1871 : int = aten::len(%1869) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1872 : int = aten::sub(%1871, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.199 : int = prim::Loop(%1872, %67, %size_prods.99) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.99 : int, %size_prods0.201 : int):
          %1876 : int = aten::add(%i.99, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1877 : int = aten::__getitem__(%1869, %1876) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.99 : int = aten::mul(%size_prods0.201, %1877) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.99)
      %1879 : bool = aten::eq(%size_prods0.199, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1879) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1880 : str = aten::format(%65, %1869) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1880, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.55 : Tensor = aten::batch_norm(%input0.79, %weight.198, %bias.198, %running_mean.99, %running_var.99, %training.197, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out.26 : Tensor = aten::gelu(%input1.55, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %depthwise_conv.26 : __torch__.torch.nn.modules.container.___torch_mangle_301.Sequential = prim::GetAttr[name="depthwise_conv"](%_12)
  %_0.78 : __torch__.torch.nn.modules.conv.___torch_mangle_300.Conv2d = prim::GetAttr[name="0"](%depthwise_conv.26)
  %_1.78 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_298.BatchNorm2d = prim::GetAttr[name="1"](%depthwise_conv.26)
  %weight.200 : Tensor = prim::GetAttr[name="weight"](%_0.78)
  %bias.200 : Tensor? = prim::GetAttr[name="bias"](%_0.78)
  %1888 : int[] = prim::ListConstruct(%66, %66)
  %1889 : int[] = prim::ListConstruct(%66, %66)
  %1890 : int[] = prim::ListConstruct(%60, %60)
  %input0.81 : Tensor = aten::conv2d(%out.26, %weight.200, %bias.200, %1888, %1889, %1890, %57) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.199 : bool = prim::GetAttr[name="training"](%_1.78)
   = prim::If(%training.199) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.101 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.78)
      %1894 : Tensor = aten::add_(%num_batches_tracked.101, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.201 : bool = prim::GetAttr[name="training"](%_1.78)
  %running_mean.101 : Tensor = prim::GetAttr[name="running_mean"](%_1.78)
  %running_var.101 : Tensor = prim::GetAttr[name="running_var"](%_1.78)
  %weight.202 : Tensor = prim::GetAttr[name="weight"](%_1.78)
  %bias.202 : Tensor = prim::GetAttr[name="bias"](%_1.78)
   = prim::If(%training.201) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1900 : int[] = aten::size(%input0.81) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.101 : int = aten::__getitem__(%1900, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1902 : int = aten::len(%1900) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1903 : int = aten::sub(%1902, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.203 : int = prim::Loop(%1903, %67, %size_prods.101) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.101 : int, %size_prods0.205 : int):
          %1907 : int = aten::add(%i.101, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1908 : int = aten::__getitem__(%1900, %1907) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.101 : int = aten::mul(%size_prods0.205, %1908) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.101)
      %1910 : bool = aten::eq(%size_prods0.203, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1910) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1911 : str = aten::format(%65, %1900) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1911, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.57 : Tensor = aten::batch_norm(%input0.81, %weight.202, %bias.202, %running_mean.101, %running_var.101, %training.201, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out0.26 : Tensor = aten::gelu(%input1.57, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %srm.26 : __torch__.___torch_mangle_306.SRMLayer = prim::GetAttr[name="srm"](%_12)
  %1915 : int[] = aten::size(%out0.26) # /home/auto_update_valid_train.py:179:21
  %b.26 : int, %c.26 : int, %1918 : int, %1919 : int = prim::ListUnpack(%1915)
  %1920 : int[] = prim::ListConstruct(%b.26, %c.26, %70)
  %1921 : Tensor = aten::view(%out0.26, %1920) # /home/auto_update_valid_train.py:182:15
  %1922 : int[] = prim::ListConstruct(%70)
  %1923 : Tensor = aten::mean(%1921, %1922, %71, %72) # /home/auto_update_valid_train.py:182:15
  %mean.26 : Tensor = aten::unsqueeze(%1923, %70) # /home/auto_update_valid_train.py:182:15
  %1925 : int[] = prim::ListConstruct(%b.26, %c.26, %70)
  %1926 : Tensor = aten::view(%out0.26, %1925) # /home/auto_update_valid_train.py:183:14
  %1927 : int[] = prim::ListConstruct(%70)
  %1928 : Tensor = aten::std(%1926, %1927, %67, %71) # /home/auto_update_valid_train.py:183:14
  %std.26 : Tensor = aten::unsqueeze(%1928, %70) # /home/auto_update_valid_train.py:183:14
  %1930 : Tensor[] = prim::ListConstruct(%mean.26, %std.26)
  %u.26 : Tensor = aten::cat(%1930, %70) # /home/auto_update_valid_train.py:184:12
  %cfc.26 : __torch__.torch.nn.modules.conv.___torch_mangle_304.Conv1d = prim::GetAttr[name="cfc"](%srm.26)
  %weight.204 : Tensor = prim::GetAttr[name="weight"](%cfc.26)
  %bias.204 : Tensor? = prim::GetAttr[name="bias"](%cfc.26)
  %1935 : int[] = prim::ListConstruct(%60)
  %1936 : int[] = prim::ListConstruct(%68)
  %1937 : int[] = prim::ListConstruct(%60)
  %z.26 : Tensor = aten::conv1d(%u.26, %weight.204, %bias.204, %1935, %1936, %1937, %57) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:370:15
  %bn.26 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_305.BatchNorm1d = prim::GetAttr[name="bn"](%srm.26)
  %training.203 : bool = prim::GetAttr[name="training"](%bn.26)
   = prim::If(%training.203) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.103 : Tensor = prim::GetAttr[name="num_batches_tracked"](%bn.26)
      %1942 : Tensor = aten::add_(%num_batches_tracked.103, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.205 : bool = prim::GetAttr[name="training"](%bn.26)
  %running_mean.103 : Tensor = prim::GetAttr[name="running_mean"](%bn.26)
  %running_var.103 : Tensor = prim::GetAttr[name="running_var"](%bn.26)
  %weight.206 : Tensor = prim::GetAttr[name="weight"](%bn.26)
  %bias.206 : Tensor = prim::GetAttr[name="bias"](%bn.26)
   = prim::If(%training.205) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1948 : int[] = aten::size(%z.26) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.103 : int = aten::__getitem__(%1948, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1950 : int = aten::len(%1948) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1951 : int = aten::sub(%1950, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.207 : int = prim::Loop(%1951, %67, %size_prods.103) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.103 : int, %size_prods0.209 : int):
          %1955 : int = aten::add(%i.103, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1956 : int = aten::__getitem__(%1948, %1955) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.103 : int = aten::mul(%size_prods0.209, %1956) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.103)
      %1958 : bool = aten::eq(%size_prods0.207, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1958) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1959 : str = aten::format(%65, %1948) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1959, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %z0.26 : Tensor = aten::batch_norm(%z.26, %weight.206, %bias.206, %running_mean.103, %running_var.103, %training.205, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %g.26 : Tensor = aten::sigmoid(%z0.26) # /home/auto_update_valid_train.py:189:12
  %1962 : int[] = prim::ListConstruct(%b.26, %c.26, %60, %60)
  %g0.26 : Tensor = aten::view(%g.26, %1962) # /home/auto_update_valid_train.py:190:12
  %1964 : Tensor = aten::expand_as(%g0.26, %out0.26) # /home/auto_update_valid_train.py:192:19
  %out1.26 : Tensor = aten::mul(%out0.26, %1964) # /home/auto_update_valid_train.py:192:15
  %project_conv.26 : __torch__.torch.nn.modules.container.___torch_mangle_303.Sequential = prim::GetAttr[name="project_conv"](%_12)
  %_0.80 : __torch__.torch.nn.modules.conv.___torch_mangle_302.Conv2d = prim::GetAttr[name="0"](%project_conv.26)
  %_1.80 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_33.BatchNorm2d = prim::GetAttr[name="1"](%project_conv.26)
  %weight.208 : Tensor = prim::GetAttr[name="weight"](%_0.80)
  %bias.208 : Tensor? = prim::GetAttr[name="bias"](%_0.80)
  %1971 : int[] = prim::ListConstruct(%60, %60)
  %1972 : int[] = prim::ListConstruct(%68, %68)
  %1973 : int[] = prim::ListConstruct(%60, %60)
  %input0.83 : Tensor = aten::conv2d(%out1.26, %weight.208, %bias.208, %1971, %1972, %1973, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.207 : bool = prim::GetAttr[name="training"](%_1.80)
   = prim::If(%training.207) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.105 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.80)
      %1977 : Tensor = aten::add_(%num_batches_tracked.105, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.209 : bool = prim::GetAttr[name="training"](%_1.80)
  %running_mean.105 : Tensor = prim::GetAttr[name="running_mean"](%_1.80)
  %running_var.105 : Tensor = prim::GetAttr[name="running_var"](%_1.80)
  %weight.210 : Tensor = prim::GetAttr[name="weight"](%_1.80)
  %bias.210 : Tensor = prim::GetAttr[name="bias"](%_1.80)
   = prim::If(%training.209) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %1983 : int[] = aten::size(%input0.83) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.105 : int = aten::__getitem__(%1983, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %1985 : int = aten::len(%1983) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %1986 : int = aten::sub(%1985, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.211 : int = prim::Loop(%1986, %67, %size_prods.105) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.105 : int, %size_prods0.213 : int):
          %1990 : int = aten::add(%i.105, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %1991 : int = aten::__getitem__(%1983, %1990) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.105 : int = aten::mul(%size_prods0.213, %1991) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.105)
      %1993 : bool = aten::eq(%size_prods0.211, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%1993) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %1994 : str = aten::format(%65, %1983) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%1994, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out2.26 : Tensor = aten::batch_norm(%input0.83, %weight.210, %bias.210, %running_mean.105, %running_var.105, %training.209, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %use_residual.26 : bool = prim::GetAttr[name="use_residual"](%_12)
  %input12.1 : Tensor = prim::If(%use_residual.26) # /home/auto_update_valid_train.py:261:8
    block0():
      %out3.26 : Tensor = aten::add(%out2.26, %input11.1, %60) # /home/auto_update_valid_train.py:263:18
      -> (%out3.26)
    block1():
      -> (%out2.26)
  %expand_conv.28 : __torch__.torch.nn.modules.container.___torch_mangle_69.Sequential = prim::GetAttr[name="expand_conv"](%_13)
  %_0.82 : __torch__.torch.nn.modules.conv.___torch_mangle_67.Conv2d = prim::GetAttr[name="0"](%expand_conv.28)
  %_1.82 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_68.BatchNorm2d = prim::GetAttr[name="1"](%expand_conv.28)
  %weight.212 : Tensor = prim::GetAttr[name="weight"](%_0.82)
  %bias.212 : Tensor? = prim::GetAttr[name="bias"](%_0.82)
  %2004 : int[] = prim::ListConstruct(%60, %60)
  %2005 : int[] = prim::ListConstruct(%68, %68)
  %2006 : int[] = prim::ListConstruct(%60, %60)
  %input0.85 : Tensor = aten::conv2d(%input12.1, %weight.212, %bias.212, %2004, %2005, %2006, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.211 : bool = prim::GetAttr[name="training"](%_1.82)
   = prim::If(%training.211) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.107 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.82)
      %2010 : Tensor = aten::add_(%num_batches_tracked.107, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.213 : bool = prim::GetAttr[name="training"](%_1.82)
  %running_mean.107 : Tensor = prim::GetAttr[name="running_mean"](%_1.82)
  %running_var.107 : Tensor = prim::GetAttr[name="running_var"](%_1.82)
  %weight.214 : Tensor = prim::GetAttr[name="weight"](%_1.82)
  %bias.214 : Tensor = prim::GetAttr[name="bias"](%_1.82)
   = prim::If(%training.213) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %2016 : int[] = aten::size(%input0.85) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.107 : int = aten::__getitem__(%2016, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %2018 : int = aten::len(%2016) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %2019 : int = aten::sub(%2018, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.215 : int = prim::Loop(%2019, %67, %size_prods.107) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.107 : int, %size_prods0.217 : int):
          %2023 : int = aten::add(%i.107, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %2024 : int = aten::__getitem__(%2016, %2023) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.107 : int = aten::mul(%size_prods0.217, %2024) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.107)
      %2026 : bool = aten::eq(%size_prods0.215, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%2026) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %2027 : str = aten::format(%65, %2016) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%2027, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.59 : Tensor = aten::batch_norm(%input0.85, %weight.214, %bias.214, %running_mean.107, %running_var.107, %training.213, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out.28 : Tensor = aten::gelu(%input1.59, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %depthwise_conv.28 : __torch__.torch.nn.modules.container.___torch_mangle_309.Sequential = prim::GetAttr[name="depthwise_conv"](%_13)
  %_0.84 : __torch__.torch.nn.modules.conv.___torch_mangle_308.Conv2d = prim::GetAttr[name="0"](%depthwise_conv.28)
  %_1.84 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_68.BatchNorm2d = prim::GetAttr[name="1"](%depthwise_conv.28)
  %weight.216 : Tensor = prim::GetAttr[name="weight"](%_0.84)
  %bias.216 : Tensor? = prim::GetAttr[name="bias"](%_0.84)
  %2035 : int[] = prim::ListConstruct(%60, %60)
  %2036 : int[] = prim::ListConstruct(%66, %66)
  %2037 : int[] = prim::ListConstruct(%60, %60)
  %input0.87 : Tensor = aten::conv2d(%out.28, %weight.216, %bias.216, %2035, %2036, %2037, %56) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.215 : bool = prim::GetAttr[name="training"](%_1.84)
   = prim::If(%training.215) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.109 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.84)
      %2041 : Tensor = aten::add_(%num_batches_tracked.109, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.217 : bool = prim::GetAttr[name="training"](%_1.84)
  %running_mean.109 : Tensor = prim::GetAttr[name="running_mean"](%_1.84)
  %running_var.109 : Tensor = prim::GetAttr[name="running_var"](%_1.84)
  %weight.218 : Tensor = prim::GetAttr[name="weight"](%_1.84)
  %bias.218 : Tensor = prim::GetAttr[name="bias"](%_1.84)
   = prim::If(%training.217) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %2047 : int[] = aten::size(%input0.87) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.109 : int = aten::__getitem__(%2047, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %2049 : int = aten::len(%2047) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %2050 : int = aten::sub(%2049, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.219 : int = prim::Loop(%2050, %67, %size_prods.109) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.109 : int, %size_prods0.221 : int):
          %2054 : int = aten::add(%i.109, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %2055 : int = aten::__getitem__(%2047, %2054) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.109 : int = aten::mul(%size_prods0.221, %2055) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.109)
      %2057 : bool = aten::eq(%size_prods0.219, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%2057) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %2058 : str = aten::format(%65, %2047) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%2058, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.61 : Tensor = aten::batch_norm(%input0.87, %weight.218, %bias.218, %running_mean.109, %running_var.109, %training.217, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out0.28 : Tensor = aten::gelu(%input1.61, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %srm.28 : __torch__.___torch_mangle_76.SRMLayer = prim::GetAttr[name="srm"](%_13)
  %2062 : int[] = aten::size(%out0.28) # /home/auto_update_valid_train.py:179:21
  %b.28 : int, %c.28 : int, %2065 : int, %2066 : int = prim::ListUnpack(%2062)
  %2067 : int[] = prim::ListConstruct(%b.28, %c.28, %70)
  %2068 : Tensor = aten::view(%out0.28, %2067) # /home/auto_update_valid_train.py:182:15
  %2069 : int[] = prim::ListConstruct(%70)
  %2070 : Tensor = aten::mean(%2068, %2069, %71, %72) # /home/auto_update_valid_train.py:182:15
  %mean.28 : Tensor = aten::unsqueeze(%2070, %70) # /home/auto_update_valid_train.py:182:15
  %2072 : int[] = prim::ListConstruct(%b.28, %c.28, %70)
  %2073 : Tensor = aten::view(%out0.28, %2072) # /home/auto_update_valid_train.py:183:14
  %2074 : int[] = prim::ListConstruct(%70)
  %2075 : Tensor = aten::std(%2073, %2074, %67, %71) # /home/auto_update_valid_train.py:183:14
  %std.28 : Tensor = aten::unsqueeze(%2075, %70) # /home/auto_update_valid_train.py:183:14
  %2077 : Tensor[] = prim::ListConstruct(%mean.28, %std.28)
  %u.28 : Tensor = aten::cat(%2077, %70) # /home/auto_update_valid_train.py:184:12
  %cfc.28 : __torch__.torch.nn.modules.conv.___torch_mangle_74.Conv1d = prim::GetAttr[name="cfc"](%srm.28)
  %weight.220 : Tensor = prim::GetAttr[name="weight"](%cfc.28)
  %bias.220 : Tensor? = prim::GetAttr[name="bias"](%cfc.28)
  %2082 : int[] = prim::ListConstruct(%60)
  %2083 : int[] = prim::ListConstruct(%68)
  %2084 : int[] = prim::ListConstruct(%60)
  %z.28 : Tensor = aten::conv1d(%u.28, %weight.220, %bias.220, %2082, %2083, %2084, %56) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:370:15
  %bn.28 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_75.BatchNorm1d = prim::GetAttr[name="bn"](%srm.28)
  %training.219 : bool = prim::GetAttr[name="training"](%bn.28)
   = prim::If(%training.219) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.111 : Tensor = prim::GetAttr[name="num_batches_tracked"](%bn.28)
      %2089 : Tensor = aten::add_(%num_batches_tracked.111, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.221 : bool = prim::GetAttr[name="training"](%bn.28)
  %running_mean.111 : Tensor = prim::GetAttr[name="running_mean"](%bn.28)
  %running_var.111 : Tensor = prim::GetAttr[name="running_var"](%bn.28)
  %weight.222 : Tensor = prim::GetAttr[name="weight"](%bn.28)
  %bias.222 : Tensor = prim::GetAttr[name="bias"](%bn.28)
   = prim::If(%training.221) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %2095 : int[] = aten::size(%z.28) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.111 : int = aten::__getitem__(%2095, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %2097 : int = aten::len(%2095) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %2098 : int = aten::sub(%2097, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.223 : int = prim::Loop(%2098, %67, %size_prods.111) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.111 : int, %size_prods0.225 : int):
          %2102 : int = aten::add(%i.111, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %2103 : int = aten::__getitem__(%2095, %2102) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.111 : int = aten::mul(%size_prods0.225, %2103) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.111)
      %2105 : bool = aten::eq(%size_prods0.223, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%2105) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %2106 : str = aten::format(%65, %2095) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%2106, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %z0.28 : Tensor = aten::batch_norm(%z.28, %weight.222, %bias.222, %running_mean.111, %running_var.111, %training.221, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %g.28 : Tensor = aten::sigmoid(%z0.28) # /home/auto_update_valid_train.py:189:12
  %2109 : int[] = prim::ListConstruct(%b.28, %c.28, %60, %60)
  %g0.28 : Tensor = aten::view(%g.28, %2109) # /home/auto_update_valid_train.py:190:12
  %2111 : Tensor = aten::expand_as(%g0.28, %out0.28) # /home/auto_update_valid_train.py:192:19
  %out1.28 : Tensor = aten::mul(%out0.28, %2111) # /home/auto_update_valid_train.py:192:15
  %project_conv.28 : __torch__.torch.nn.modules.container.___torch_mangle_311.Sequential = prim::GetAttr[name="project_conv"](%_13)
  %_0.86 : __torch__.torch.nn.modules.conv.___torch_mangle_310.Conv2d = prim::GetAttr[name="0"](%project_conv.28)
  %_1.86 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_33.BatchNorm2d = prim::GetAttr[name="1"](%project_conv.28)
  %weight.224 : Tensor = prim::GetAttr[name="weight"](%_0.86)
  %bias.224 : Tensor? = prim::GetAttr[name="bias"](%_0.86)
  %2118 : int[] = prim::ListConstruct(%60, %60)
  %2119 : int[] = prim::ListConstruct(%68, %68)
  %2120 : int[] = prim::ListConstruct(%60, %60)
  %input0.89 : Tensor = aten::conv2d(%out1.28, %weight.224, %bias.224, %2118, %2119, %2120, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.223 : bool = prim::GetAttr[name="training"](%_1.86)
   = prim::If(%training.223) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.113 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.86)
      %2124 : Tensor = aten::add_(%num_batches_tracked.113, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.225 : bool = prim::GetAttr[name="training"](%_1.86)
  %running_mean.113 : Tensor = prim::GetAttr[name="running_mean"](%_1.86)
  %running_var.113 : Tensor = prim::GetAttr[name="running_var"](%_1.86)
  %weight.226 : Tensor = prim::GetAttr[name="weight"](%_1.86)
  %bias.226 : Tensor = prim::GetAttr[name="bias"](%_1.86)
   = prim::If(%training.225) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %2130 : int[] = aten::size(%input0.89) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.113 : int = aten::__getitem__(%2130, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %2132 : int = aten::len(%2130) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %2133 : int = aten::sub(%2132, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.227 : int = prim::Loop(%2133, %67, %size_prods.113) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.113 : int, %size_prods0.229 : int):
          %2137 : int = aten::add(%i.113, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %2138 : int = aten::__getitem__(%2130, %2137) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.113 : int = aten::mul(%size_prods0.229, %2138) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.113)
      %2140 : bool = aten::eq(%size_prods0.227, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%2140) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %2141 : str = aten::format(%65, %2130) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%2141, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out2.28 : Tensor = aten::batch_norm(%input0.89, %weight.226, %bias.226, %running_mean.113, %running_var.113, %training.225, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %use_residual.28 : bool = prim::GetAttr[name="use_residual"](%_13)
  %input13.1 : Tensor = prim::If(%use_residual.28) # /home/auto_update_valid_train.py:261:8
    block0():
      %out3.28 : Tensor = aten::add(%out2.28, %input12.1, %60) # /home/auto_update_valid_train.py:263:18
      -> (%out3.28)
    block1():
      -> (%out2.28)
  %expand_conv.1 : __torch__.torch.nn.modules.container.___torch_mangle_173.Sequential = prim::GetAttr[name="expand_conv"](%_14)
  %_0.1 : __torch__.torch.nn.modules.conv.___torch_mangle_171.Conv2d = prim::GetAttr[name="0"](%expand_conv.1)
  %_1.1 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_172.BatchNorm2d = prim::GetAttr[name="1"](%expand_conv.1)
  %weight.3 : Tensor = prim::GetAttr[name="weight"](%_0.1)
  %bias.3 : Tensor? = prim::GetAttr[name="bias"](%_0.1)
  %2151 : int[] = prim::ListConstruct(%60, %60)
  %2152 : int[] = prim::ListConstruct(%68, %68)
  %2153 : int[] = prim::ListConstruct(%60, %60)
  %input0.2 : Tensor = aten::conv2d(%input13.1, %weight.3, %bias.3, %2151, %2152, %2153, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.2 : bool = prim::GetAttr[name="training"](%_1.1)
   = prim::If(%training.2) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.2 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.1)
      %2157 : Tensor = aten::add_(%num_batches_tracked.2, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.4 : bool = prim::GetAttr[name="training"](%_1.1)
  %running_mean.2 : Tensor = prim::GetAttr[name="running_mean"](%_1.1)
  %running_var.2 : Tensor = prim::GetAttr[name="running_var"](%_1.1)
  %weight.5 : Tensor = prim::GetAttr[name="weight"](%_1.1)
  %bias.5 : Tensor = prim::GetAttr[name="bias"](%_1.1)
   = prim::If(%training.4) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %2163 : int[] = aten::size(%input0.2) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.2 : int = aten::__getitem__(%2163, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %2165 : int = aten::len(%2163) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %2166 : int = aten::sub(%2165, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.1 : int = prim::Loop(%2166, %67, %size_prods.2) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.2 : int, %size_prods0.8 : int):
          %2170 : int = aten::add(%i.2, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %2171 : int = aten::__getitem__(%2163, %2170) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.2 : int = aten::mul(%size_prods0.8, %2171) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.2)
      %2173 : bool = aten::eq(%size_prods0.1, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%2173) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %2174 : str = aten::format(%65, %2163) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%2174, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.2 : Tensor = aten::batch_norm(%input0.2, %weight.5, %bias.5, %running_mean.2, %running_var.2, %training.4, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out.1 : Tensor = aten::gelu(%input1.2, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %depthwise_conv.1 : __torch__.torch.nn.modules.container.___torch_mangle_175.Sequential = prim::GetAttr[name="depthwise_conv"](%_14)
  %_0.3 : __torch__.torch.nn.modules.conv.___torch_mangle_174.Conv2d = prim::GetAttr[name="0"](%depthwise_conv.1)
  %_1.3 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_172.BatchNorm2d = prim::GetAttr[name="1"](%depthwise_conv.1)
  %weight.7 : Tensor = prim::GetAttr[name="weight"](%_0.3)
  %bias.7 : Tensor? = prim::GetAttr[name="bias"](%_0.3)
  %2182 : int[] = prim::ListConstruct(%66, %66)
  %2183 : int[] = prim::ListConstruct(%60, %60)
  %2184 : int[] = prim::ListConstruct(%60, %60)
  %input0.4 : Tensor = aten::conv2d(%out.1, %weight.7, %bias.7, %2182, %2183, %2184, %55) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.6 : bool = prim::GetAttr[name="training"](%_1.3)
   = prim::If(%training.6) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.4 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.3)
      %2188 : Tensor = aten::add_(%num_batches_tracked.4, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.8 : bool = prim::GetAttr[name="training"](%_1.3)
  %running_mean.4 : Tensor = prim::GetAttr[name="running_mean"](%_1.3)
  %running_var.4 : Tensor = prim::GetAttr[name="running_var"](%_1.3)
  %weight.9 : Tensor = prim::GetAttr[name="weight"](%_1.3)
  %bias.9 : Tensor = prim::GetAttr[name="bias"](%_1.3)
   = prim::If(%training.8) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %2194 : int[] = aten::size(%input0.4) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.4 : int = aten::__getitem__(%2194, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %2196 : int = aten::len(%2194) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %2197 : int = aten::sub(%2196, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.10 : int = prim::Loop(%2197, %67, %size_prods.4) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.4 : int, %size_prods0.12 : int):
          %2201 : int = aten::add(%i.4, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %2202 : int = aten::__getitem__(%2194, %2201) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.4 : int = aten::mul(%size_prods0.12, %2202) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.4)
      %2204 : bool = aten::eq(%size_prods0.10, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%2204) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %2205 : str = aten::format(%65, %2194) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%2205, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input1.1 : Tensor = aten::batch_norm(%input0.4, %weight.9, %bias.9, %running_mean.4, %running_var.4, %training.8, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %out0.1 : Tensor = aten::gelu(%input1.1, %61) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:734:15
  %srm.1 : __torch__.___torch_mangle_180.SRMLayer = prim::GetAttr[name="srm"](%_14)
  %2209 : int[] = aten::size(%out0.1) # /home/auto_update_valid_train.py:179:21
  %b.1 : int, %c.1 : int, %2212 : int, %2213 : int = prim::ListUnpack(%2209)
  %2214 : int[] = prim::ListConstruct(%b.1, %c.1, %70)
  %2215 : Tensor = aten::view(%out0.1, %2214) # /home/auto_update_valid_train.py:182:15
  %2216 : int[] = prim::ListConstruct(%70)
  %2217 : Tensor = aten::mean(%2215, %2216, %71, %72) # /home/auto_update_valid_train.py:182:15
  %mean.1 : Tensor = aten::unsqueeze(%2217, %70) # /home/auto_update_valid_train.py:182:15
  %2219 : int[] = prim::ListConstruct(%b.1, %c.1, %70)
  %2220 : Tensor = aten::view(%out0.1, %2219) # /home/auto_update_valid_train.py:183:14
  %2221 : int[] = prim::ListConstruct(%70)
  %2222 : Tensor = aten::std(%2220, %2221, %67, %71) # /home/auto_update_valid_train.py:183:14
  %std.1 : Tensor = aten::unsqueeze(%2222, %70) # /home/auto_update_valid_train.py:183:14
  %2224 : Tensor[] = prim::ListConstruct(%mean.1, %std.1)
  %u.1 : Tensor = aten::cat(%2224, %70) # /home/auto_update_valid_train.py:184:12
  %cfc.1 : __torch__.torch.nn.modules.conv.___torch_mangle_178.Conv1d = prim::GetAttr[name="cfc"](%srm.1)
  %weight.11 : Tensor = prim::GetAttr[name="weight"](%cfc.1)
  %bias.11 : Tensor? = prim::GetAttr[name="bias"](%cfc.1)
  %2229 : int[] = prim::ListConstruct(%60)
  %2230 : int[] = prim::ListConstruct(%68)
  %2231 : int[] = prim::ListConstruct(%60)
  %z.1 : Tensor = aten::conv1d(%u.1, %weight.11, %bias.11, %2229, %2230, %2231, %55) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:370:15
  %bn.1 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_179.BatchNorm1d = prim::GetAttr[name="bn"](%srm.1)
  %training.10 : bool = prim::GetAttr[name="training"](%bn.1)
   = prim::If(%training.10) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.6 : Tensor = prim::GetAttr[name="num_batches_tracked"](%bn.1)
      %2236 : Tensor = aten::add_(%num_batches_tracked.6, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training.12 : bool = prim::GetAttr[name="training"](%bn.1)
  %running_mean.6 : Tensor = prim::GetAttr[name="running_mean"](%bn.1)
  %running_var.6 : Tensor = prim::GetAttr[name="running_var"](%bn.1)
  %weight.13 : Tensor = prim::GetAttr[name="weight"](%bn.1)
  %bias.13 : Tensor = prim::GetAttr[name="bias"](%bn.1)
   = prim::If(%training.12) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %2242 : int[] = aten::size(%z.1) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.6 : int = aten::__getitem__(%2242, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %2244 : int = aten::len(%2242) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %2245 : int = aten::sub(%2244, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0.14 : int = prim::Loop(%2245, %67, %size_prods.6) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.6 : int, %size_prods0.16 : int):
          %2249 : int = aten::add(%i.6, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %2250 : int = aten::__getitem__(%2242, %2249) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.6 : int = aten::mul(%size_prods0.16, %2250) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.6)
      %2252 : bool = aten::eq(%size_prods0.14, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%2252) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %2253 : str = aten::format(%65, %2242) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%2253, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %z0.1 : Tensor = aten::batch_norm(%z.1, %weight.13, %bias.13, %running_mean.6, %running_var.6, %training.12, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %g.1 : Tensor = aten::sigmoid(%z0.1) # /home/auto_update_valid_train.py:189:12
  %2256 : int[] = prim::ListConstruct(%b.1, %c.1, %60, %60)
  %g0.1 : Tensor = aten::view(%g.1, %2256) # /home/auto_update_valid_train.py:190:12
  %2258 : Tensor = aten::expand_as(%g0.1, %out0.1) # /home/auto_update_valid_train.py:192:19
  %out1.1 : Tensor = aten::mul(%out0.1, %2258) # /home/auto_update_valid_train.py:192:15
  %project_conv.1 : __torch__.torch.nn.modules.container.___torch_mangle_177.Sequential = prim::GetAttr[name="project_conv"](%_14)
  %_0 : __torch__.torch.nn.modules.conv.___torch_mangle_176.Conv2d = prim::GetAttr[name="0"](%project_conv.1)
  %_1 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_50.BatchNorm2d = prim::GetAttr[name="1"](%project_conv.1)
  %weight.2 : Tensor = prim::GetAttr[name="weight"](%_0)
  %bias.2 : Tensor? = prim::GetAttr[name="bias"](%_0)
  %2265 : int[] = prim::ListConstruct(%60, %60)
  %2266 : int[] = prim::ListConstruct(%68, %68)
  %2267 : int[] = prim::ListConstruct(%60, %60)
  %input0.1 : Tensor = aten::conv2d(%out1.1, %weight.2, %bias.2, %2265, %2266, %2267, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:15
  %training.18 : bool = prim::GetAttr[name="training"](%_1)
   = prim::If(%training.18) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:170:11
    block0():
      %num_batches_tracked.1 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1)
      %2271 : Tensor = aten::add_(%num_batches_tracked.1, %60, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:173:16
      -> ()
    block1():
      -> ()
  %training : bool = prim::GetAttr[name="training"](%_1)
  %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%_1)
  %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%_1)
  %weight.19 : Tensor = prim::GetAttr[name="weight"](%_1)
  %bias.19 : Tensor = prim::GetAttr[name="bias"](%_1)
   = prim::If(%training) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2809:4
    block0():
      %2277 : int[] = aten::size(%input0.1) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2810:27
      %size_prods.1 : int = aten::__getitem__(%2277, %68) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2772:17
      %2279 : int = aten::len(%2277) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %2280 : int = aten::sub(%2279, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:19
      %size_prods0 : int = prim::Loop(%2280, %67, %size_prods.1) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2773:4
        block0(%i.1 : int, %size_prods0.7 : int):
          %2284 : int = aten::add(%i.1, %66) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:27
          %2285 : int = aten::__getitem__(%2277, %2284) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:22
          %size_prods1.1 : int = aten::mul(%size_prods0.7, %2285) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2774:8
          -> (%67, %size_prods1.1)
      %2287 : bool = aten::eq(%size_prods0, %60) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:7
       = prim::If(%2287) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2775:4
        block0():
          %2288 : str = aten::format(%65, %2277) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2777:12
           = prim::RaiseException(%2288, %64) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2776:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out2.1 : Tensor = aten::batch_norm(%input0.1, %weight.19, %bias.19, %running_mean.1, %running_var.1, %training, %62, %63, %67) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:11
  %use_residual.1 : bool = prim::GetAttr[name="use_residual"](%_14)
  %x1.1 : Tensor = prim::If(%use_residual.1) # /home/auto_update_valid_train.py:261:8
    block0():
      %out3.1 : Tensor = aten::add(%out2.1, %input13.1, %60) # /home/auto_update_valid_train.py:263:18
      -> (%out3.1)
    block1():
      -> (%out2.1)
  %10 : int[] = prim::ListConstruct(%4, %5)
  %x2.1 : Tensor = aten::mean(%x1.1, %10, %3, %2) # /home/auto_update_valid_train.py:300:12
  %dropout.1 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="dropout"](%self.1)
  %2293 : float = prim::Constant[value=0.10000000000000001]() # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/dropout.py:70:32
  %training.1 : bool = prim::GetAttr[name="training"](%dropout.1)
  %x3.1 : Tensor = aten::dropout(%x2.1, %2293, %training.1) # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1425:57
  %classifier.1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="classifier"](%self.1)
  %weight.1 : Tensor = prim::GetAttr[name="weight"](%classifier.1)
  %bias.1 : Tensor = prim::GetAttr[name="bias"](%classifier.1)
  %2298 : Tensor = aten::linear(%x3.1, %weight.1, %bias.1) # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:125:15
  return (%2298)
